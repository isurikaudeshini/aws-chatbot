{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    \"https://localhost:9200\",\n",
    "    basic_auth=(\"elastic\",\"3TgCUfRLY3o7BXKYpWFs\"),\n",
    "    ca_certs=\"/home/isurika/downloads/elasticsearch-8.12.0/config/certs/http_ca.crt\"\n",
    ")\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I run a web server on AWS?</td>\n",
       "      <td>To run a web server on AWS, you can use Amazon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What AWS service should I use to host a scalab...</td>\n",
       "      <td>For hosting scalable applications, consider us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How do I deploy a custom application on the cl...</td>\n",
       "      <td>To deploy a custom application, use Amazon EC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I need a dedicated environment for my applicat...</td>\n",
       "      <td>If you need dedicated resources for your appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What's the best way to get started with virtua...</td>\n",
       "      <td>Start with Amazon EC2. It offers a wide range ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            pattern  \\\n",
       "0   1                 How can I run a web server on AWS?   \n",
       "1   2  What AWS service should I use to host a scalab...   \n",
       "2   3  How do I deploy a custom application on the cl...   \n",
       "3   4  I need a dedicated environment for my applicat...   \n",
       "4   5  What's the best way to get started with virtua...   \n",
       "\n",
       "                                            response  \n",
       "0  To run a web server on AWS, you can use Amazon...  \n",
       "1  For hosting scalable applications, consider us...  \n",
       "2  To deploy a custom application, use Amazon EC2...  \n",
       "3  If you need dedicated resources for your appli...  \n",
       "4  Start with Amazon EC2. It offers a wide range ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/mnt/d/University/repos/aws-chatbot/dataset/consolidated_data.csv\").loc[:2488]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NA values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     pattern  response\n",
       "False  False    False       1254\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the relevant field to Vector using BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer                                                                                                                                                                               # type: ignore\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ResponseVector\"] = df[\"response\"].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "      <th>ResponseVector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I run a web server on AWS?</td>\n",
       "      <td>To run a web server on AWS, you can use Amazon...</td>\n",
       "      <td>[-0.00054931047, -0.05692641, -0.0006814774, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What AWS service should I use to host a scalab...</td>\n",
       "      <td>For hosting scalable applications, consider us...</td>\n",
       "      <td>[-0.015269826, -0.012294186, -0.01100238, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How do I deploy a custom application on the cl...</td>\n",
       "      <td>To deploy a custom application, use Amazon EC2...</td>\n",
       "      <td>[-0.012933653, -0.045452587, -0.0068273027, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I need a dedicated environment for my applicat...</td>\n",
       "      <td>If you need dedicated resources for your appli...</td>\n",
       "      <td>[-0.009388072, -0.018510194, 0.0007667323, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What's the best way to get started with virtua...</td>\n",
       "      <td>Start with Amazon EC2. It offers a wide range ...</td>\n",
       "      <td>[-0.059143938, -0.017358141, -0.0022847152, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            pattern  \\\n",
       "0   1                 How can I run a web server on AWS?   \n",
       "1   2  What AWS service should I use to host a scalab...   \n",
       "2   3  How do I deploy a custom application on the cl...   \n",
       "3   4  I need a dedicated environment for my applicat...   \n",
       "4   5  What's the best way to get started with virtua...   \n",
       "\n",
       "                                            response  \\\n",
       "0  To run a web server on AWS, you can use Amazon...   \n",
       "1  For hosting scalable applications, consider us...   \n",
       "2  To deploy a custom application, use Amazon EC2...   \n",
       "3  If you need dedicated resources for your appli...   \n",
       "4  Start with Amazon EC2. It offers a wide range ...   \n",
       "\n",
       "                                      ResponseVector  \n",
       "0  [-0.00054931047, -0.05692641, -0.0006814774, 0...  \n",
       "1  [-0.015269826, -0.012294186, -0.01100238, -0.0...  \n",
       "2  [-0.012933653, -0.045452587, -0.0068273027, -0...  \n",
       "3  [-0.009388072, -0.018510194, 0.0007667323, 0.0...  \n",
       "4  [-0.059143938, -0.017358141, -0.0022847152, -0...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new index in ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexMapping import indexMapping\n",
    "\n",
    "try:\n",
    "    es.indices.create(index=\"all_patterns_v1\", mappings=indexMapping) \n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest the data into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in record_list:\n",
    "    try:\n",
    "        es.index(index=\"all_patterns_1500\", document=record, id=record[\"id\"])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 1501, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index=\"all_patterns_1500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Matching Result:\n",
      "Pattern: When does billing of my Amazon EC2 systems begin and end?\n",
      "Response: Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don't charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375001/864556165.py:11: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  res = es.knn_search(index=\"all_patterns_1500\", knn=query, source=[\"pattern\", \"response\"])\n"
     ]
    }
   ],
   "source": [
    "input_keyword = \" Billing of Amazon EC2 systems begin and end?\"\n",
    "vector_of_input_keyword = model.encode(input_keyword)\n",
    "\n",
    "query = {\n",
    "    \"field\": \"ResponseVector\",\n",
    "    \"query_vector\": vector_of_input_keyword,\n",
    "    \"k\": 1,  # Set k to 1 to get only the top result\n",
    "    \"num_candidates\": 1500,\n",
    "}\n",
    "\n",
    "res = es.knn_search(index=\"all_patterns_1500\", knn=query, source=[\"pattern\", \"response\"])\n",
    "hits = res[\"hits\"][\"hits\"]\n",
    "\n",
    "\n",
    "if hits:\n",
    "    best_match = hits[0]\n",
    "    print(\"Best Matching Result:\")\n",
    "    print(\"Pattern:\", best_match[\"_source\"][\"pattern\"])\n",
    "    print(\"Response:\", best_match[\"_source\"][\"response\"])\n",
    "else:\n",
    "    print(\"No matching results found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375001/1260241245.py:11: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_index': 'all_patterns_1500',\n",
       "  '_id': '339',\n",
       "  '_score': 0.90958804,\n",
       "  '_ignored': ['response.keyword'],\n",
       "  '_source': {'pattern': 'When does billing of my Amazon EC2 systems begin and end?',\n",
       "   'response': 'Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don\\'t charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.'}},\n",
       " {'_index': 'all_patterns_1500',\n",
       "  '_id': '340',\n",
       "  '_score': 0.84812176,\n",
       "  '_ignored': ['response.keyword'],\n",
       "  '_source': {'pattern': 'What defines billable EC2 instance usage?',\n",
       "   'response': 'Instance usages are billed for any time your instances are in a \"running\" state. If you no longer wish to be charged for your instance, you must \"stop\" or \"terminate\" the instance to avoid being billed for additional instance usage. Billing starts when an instance transitions into the running state.'}},\n",
       " {'_index': 'all_patterns_1500',\n",
       "  '_id': '343',\n",
       "  '_score': 0.8385503,\n",
       "  '_ignored': ['response.keyword'],\n",
       "  '_source': {'pattern': 'How will my monthly bill show per-second versus per-hour?',\n",
       "   'response': 'Although EC2 charges in your monthly bill will now be calculated based on a per second basis, for consistency, the monthly EC2 bill will show cumulative usage for each instance that ran in a given month in decimal hours. For example, an instance running for 1 hour 10 minutes and 4 seconds would look like 1.1677. Read this blog for an example of the detailed billing report.'}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_keyword = \"Billing of Amazon EC2 systems begin and end?\"\n",
    "vector_of_input_keyword = model.encode(input_keyword)\n",
    "\n",
    "query = {\n",
    "    \"field\" : \"ResponseVector\",\n",
    "    \"query_vector\" : vector_of_input_keyword,\n",
    "    \"k\" : 3,\n",
    "    \"num_candidates\" : 1500, \n",
    "}\n",
    "\n",
    "res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n",
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = df.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pattern</th>\n",
       "      <th>response</th>\n",
       "      <th>ResponseVector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1248</td>\n",
       "      <td>Are there any limitations for using S3 Replica...</td>\n",
       "      <td>No, all features of S3 Replication, such as S3...</td>\n",
       "      <td>[0.018218152, -0.030392952, -0.0015461136, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155</td>\n",
       "      <td>Which AMIs are supported on Hpc7a instances?</td>\n",
       "      <td>Hpc7a instances support Amazon Linux 2, Amazon...</td>\n",
       "      <td>[-0.015100935, -0.04661958, 0.035087906, 0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1146</td>\n",
       "      <td>Storage Example:</td>\n",
       "      <td>Assume you store 100 GB (107,374,182,400 bytes...</td>\n",
       "      <td>[0.03666824, -0.028377365, -0.0135443825, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>How can I optimize costs for my application wi...</td>\n",
       "      <td>Use a combination of Reserved Instances for ba...</td>\n",
       "      <td>[0.0154247, -0.03015373, -0.05171402, -0.00068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>How do I purchase an RI?</td>\n",
       "      <td>To get started, you can purchase an RI from th...</td>\n",
       "      <td>[0.03952223, -0.043768782, -0.013615112, -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            pattern  \\\n",
       "1247  1248  Are there any limitations for using S3 Replica...   \n",
       "154    155       Which AMIs are supported on Hpc7a instances?   \n",
       "1145  1146                                   Storage Example:   \n",
       "33      34  How can I optimize costs for my application wi...   \n",
       "413    414                           How do I purchase an RI?   \n",
       "\n",
       "                                               response  \\\n",
       "1247  No, all features of S3 Replication, such as S3...   \n",
       "154   Hpc7a instances support Amazon Linux 2, Amazon...   \n",
       "1145  Assume you store 100 GB (107,374,182,400 bytes...   \n",
       "33    Use a combination of Reserved Instances for ba...   \n",
       "413   To get started, you can purchase an RI from th...   \n",
       "\n",
       "                                         ResponseVector  \n",
       "1247  [0.018218152, -0.030392952, -0.0015461136, 0.0...  \n",
       "154   [-0.015100935, -0.04661958, 0.035087906, 0.024...  \n",
       "1145  [0.03666824, -0.028377365, -0.0135443825, 0.01...  \n",
       "33    [0.0154247, -0.03015373, -0.05171402, -0.00068...  \n",
       "413   [0.03952223, -0.043768782, -0.013615112, -0.01...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(input_keyword):\n",
    "    # model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    # input_keyword = \"Billing of Amazon EC2 systems begin and end?\"\n",
    "    vector_of_input_keyword = model.encode(input_keyword)\n",
    "\n",
    "    query = {\n",
    "        \"field\" : \"ResponseVector\",\n",
    "        \"query_vector\" : vector_of_input_keyword,\n",
    "        \"k\" : 3,\n",
    "        \"num_candidates\" : 1500, \n",
    "    }\n",
    "\n",
    "    res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n",
    "    results = res[\"hits\"][\"hits\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375001/576961223.py:13: ElasticsearchWarning: The kNN search API has been replaced by the `knn` option in the search API.\n",
      "  res = es.knn_search(index=\"all_patterns_1500\", knn=query , source=[\"pattern\",\"response\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: Do I need additional permissions to replicate objects from buckets with S3 Object Lock enabled? \n",
      "Response: Yes, to replicate objects from S3 Object Lock enabled buckets you need to grant two new permissions, s3:GetObjectRetention and s3:GetObjectLegalHold, on the source bucket in the IAM role that you use to set up replication. Alternatively, if the IAM role has an s3:Get* permission, it satisfies the requirement. For more information see the documentation on using S3 Object Lock with S3 Replication.\n",
      "Pattern: Which AMIs are supported on Hpc7a instances? \n",
      "Response: Hpc7a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.6 or later, SUSE Linux Enterprise Server 12 SP3 or later, CentOS 7 or later, and FreeBSD 11.1 or later.\n",
      "Pattern: How do dense HDD-storage instances differ from Amazon EBS? \n",
      "Response: Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2 while abstracting the details of the underlying storage media in use. Amazon EC2 instance instances with local HDD or NVMe storage provide directly attached, high performance storage building blocks that can be used for a variety of storage applications. Dense-storage instances are specifically targeted at customers who want high sequential read/write access to large data sets on local storage, e.g. for Hadoop distributed computing and massively parallel processing data warehousing.\n",
      "Pattern: I have a workload with variable demand. What EC2 option would be cost-effective and scalable? \n",
      "Response: For variable demand workloads, a combination of On-Demand and Spot Instances can be cost-effective. Use On-Demand for baseline capacity and Spot Instances to handle spikes in demand.\n",
      "Pattern: How do I purchase an RI? \n",
      "Response: To get started, you can purchase an RI from the EC2 console or by using the AWS CLI. Simply specify the instance type, platform, tenancy, term, payment option, and region or AZ.\n",
      "Pattern: Can I prioritize access to an On-Demand Capacity Reservation among the AWS accounts that have shared access? \n",
      "Response: No. Instance spots in an On-Demand Capacity Reservation are available on a first-come, first-served basis to any account that has shared access.\n",
      "Pattern: What are the differences between an EFA ENI and an ENA ENI? \n",
      "Response: An ENA ENI provides traditional IP networking features necessary to support VPC networking. An EFA ENI provides all the functionality of an ENA ENI, plus hardware support for applications to communicate directly with the EFA ENI without involving the instance kernel (OS-bypass communication) using an extended programming interface. Due to the advanced capabilities of the EFA ENI, EFA ENIs can only be attached at launch or to stopped instances.\n",
      "Pattern: When should I purchase a Convertible RI instead of a Standard RI? \n",
      "Response: The Convertible RI is useful for customers who can commit to using EC2 instances for a three-year term in exchange for a significant discount on their EC2 usage, are uncertain about their instance needs in the future, or want to benefit from changes in price.\n",
      "Pattern: I have large datasets for analytics. What AWS service can I use to efficiently analyze data stored in S3? \n",
      "Response: Use Amazon Athena for querying and analyzing data directly from Amazon S3 without the need for data loading.\n",
      "Pattern: Can I change the instance type of my RI during its term? \n",
      "Response: Yes. Convertible RIs offer you the option to change the instance type, operating system, tenancy or payment option of your RI during its term. Please refer to the Convertible RI section of the FAQ for additional information.\n",
      "Pattern: What types of Savings Plans does AWS offer? \n",
      "Response: AWS offers two types of Savings Plans:\n",
      "Pattern: My application requires dedicated hardware due to licensing restrictions. What option should I choose? \n",
      "Response: Opt for Dedicated Hosts if your application has licensing restrictions that require you to run on dedicated physical servers.\n",
      "Pattern: What are IAM policies? \n",
      "Response: IAM policies define permissions for the entities you attach them to. For example, to grant access to an IAM role, attach a policy to the role. The permissions defined in the policy determine whether requests are allowed or denied. You also can attach policies to some resources, such as Amazon S3 buckets, to grant direct, cross-account access. And you can attach policies to an AWS organization or organizational unit to restrict access across multiple accounts. AWS evaluates these policies when an IAM role makes a request. For more information, see Identity-based policies.\n",
      "Pattern: What is AWS Fargate? \n",
      "Response: AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). AWS Fargate makes it easy to focus on building your applications by eliminating the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design. \n",
      "Pattern: How can I integrate my Amazon RDS database with other AWS services for data analytics? \n",
      "Response: Use Amazon RDS with Amazon Redshift for seamless integration with data analytics services, enabling efficient data processing and analysis.\n",
      "Pattern: What is the pricing of AWS Lambda functions powered by AWS Graviton2 processors? Does the AWS Lambda free tier apply to functions powered by Graviton2? \n",
      "Response: AWS Lambda functions powered by AWS Graviton2 processors are 20% cheaper compared to x86-based Lambda functions. The Lambda free tier applies to AWS Lambda functions powered by x86 and Arm-based architectures. \n",
      "Pattern: Are there any ways to optimize the likelihood that I receive the full number of instances I request for my cluster via a cluster placement group? \n",
      "Response: We recommend that you launch the minimum number of instances required to participate in a cluster in a single launch. For very large clusters, you should launch multiple placement groups, e.g. two placement groups of 128 instances, and combine them to create a larger, 256 instance cluster.\n",
      "Pattern: I have a mobile application that requires storage for user uploads. Which AWS service should I use? \n",
      "Response: Amazon S3 is suitable for storing and serving user uploads in a scalable and cost-effective manner for your mobile application.\n",
      "Pattern: Is data stored on Amazon EC2 NVMe instance storage encrypted? \n",
      "Response: Yes, all data is encrypted in an AWS Nitro hardware module prior to being written on the locally attached SSDs offered via NVMe instance storage.\n",
      "Pattern: What AWS regions are available for AWS Lambda? \n",
      "Response: Please refer to the AWS Global Infrastructure Region Table. \n",
      "Pattern: How do I select the right instance type? \n",
      "Response: Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance or burstable performance; Compute Optimized instances have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerated Computing instances use hardware accelerators, or co-processors, to perform functions such as floating point number calculations, graphics processing, or data pattern matching, more efficiently than is possible in software running on CPUs; Storage Optimized Instances provide low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, as well as dense HDD-storage instances, which provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size.\n",
      "Pattern: How can I ensure my Amazon RDS database is highly available across different geographic regions? \n",
      "Response: Utilize Amazon RDS Cross-Region Read Replicas to enhance availability by replicating your database to a different AWS region.\n",
      "Pattern: How do I configure my Lambda function to use Lambda SnapStart? \n",
      "Response: Lambda SnapStart is a simple function level configuration that can be configured for new and existing Java functions by using Lambda API, the AWS Management Console, AWS Command Line Interface (CLI), AWS SDK, AWS Cloud Development Kit (CDK), AWS CloudFormation, and the AWS Serverless Application Model (SAM). When you configure Lambda SnapStart, every function version that is published thereafter benefits from the improved startup performance offered by Lambda SnapStart. To learn more about Lambda SnapStart, see the documentation. \n",
      "Pattern: What use cases does Amazon RDS Proxy address? \n",
      "Response: Amazon RDS Proxy addresses a number of use cases related to scalability, availability, and security of your applications, including: Applications with unpredictable workloads: Applications that support highly variable workloads may attempt to open a burst of new database connections. Amazon RDS Proxy's connection governance allows you to gracefully scale applications dealing with unpredictable workloads by efficiently reusing database connections. First, RDS Proxy enables multiple application connections to share a database connection for efficient use of database resources. Second, RDS Proxy allows you to maintain predictable database performance by regulating the number of database connections that are opened. Third, RDS Proxy removes requests that cannot be served to preserve the overall performance and availability of the application. Applications that frequently open and close database connections: Applications built on technologies such as Serverless, PHP, or Ruby on Rails may open and close database connections frequently to serve application requests. Amazon RDS Proxy maintains a pool of database connections to avoid unnecessary stress on database compute and memory for establishing new connections. Applications that keep connections open but idle: Applications in industries such as SaaS or eCommerce may keep database connections idling to minimize the response time when a customer reengages. Instead of overprovisioning databases to support mostly idling connections, you can use Amazon RDS Proxy to hold idling connections while only establishing database connections as required to optimally serve active requests. Applications requiring availability through transient failures: With Amazon RDS Proxy, you can build applications that can transparently tolerate database failures without needing to write complex failure handling code. RDS Proxy automatically routes traffic to a new database instance while preserving application connections. RDS Proxy also bypasses Domain Name System (DNS) caches to reduce failover times by up to 66% for Amazon RDS and Aurora Multi-AZ databases. During database failovers, the application may experience increased latencies and ongoing transactions may have to be retried. Improved security and centralized credentials management: Amazon RDS Proxy aids you in building more secure applications by giving you a choice to enforce IAM based authentication with relational databases. RDS Proxy also enables you to centrally manage database credentials through AWS Secrets Manager. \n",
      "Pattern: Which instances and operating systems support hibernation? \n",
      "Response: Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.\n",
      "Pattern: What is VM Import/Export? \n",
      "Response: VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.\n",
      "Pattern: When does billing of my Amazon EC2 systems begin and end? \n",
      "Response: Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don't charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.\n",
      "Pattern: What is a Spot fleet? \n",
      "Response: A Spot Fleet allows you to automatically request and manage multiple Spot instances that provide the lowest price per unit of capacity for your cluster or application, like a batch processing job, a Hadoop workflow, or an HPC grid computing job. You can include the instance types that your application can use. You define a target capacity based on your application needs (in units including instances, vCPUs, memory, storage, or network throughput) and update the target capacity after the fleet is launched. Spot fleets enable you to launch and maintain the target capacity, and to automatically request resources to replace any that are disrupted or manually terminated. Learn more about Spot fleets.\n",
      "Pattern: Do I need to enable automatic backups on my DB instance before I can create read replicas? \n",
      "Response: Yes. Enable automatic backups on your source DB Instance before adding read replicas by setting the backup retention period to a value other than 0. Backups must remain enabled for read replicas to work. \n",
      "Pattern: Will there be changes to pricing and billing when previous generation instances are migrated to AWS Nitro System? \n",
      "Response: There will be no change to billing and pricing. We will continue to support the same pricing models we support today for the previous generation instances (On-Demand, 1yr/3yr Reserved Instance, Savings Plan, Spot).\n",
      "Pattern: Can I associate more than one Amazon EFS file system with my AWS Lambda function? \n",
      "Response: No. Each Lambda function will be able to access one EFS file system. \n",
      "Pattern: If I sell my RI in the RI Marketplace, will I get refunded for the Premium Support I was charged, too? \n",
      "Response: No, you will not receive a prorated refund for the upfront portion of the AWS Premium Support Fee.\n",
      "Pattern: Are Spot fleet requests guaranteed to be fulfilled? \n",
      "Response: No. Spot fleet requests allow you to place multiple Spot Instance requests simultaneously, and are subject to the same availability and prices as a single Spot Instance request. For example, if no resources are available for the instance types listed in your Spot Fleet request, we may be unable to fulfill your request partially or in full. We recommend that you to include all the possible instance types and availability zones that are suitable for your workloads in the Spot Fleet.\n",
      "Pattern: I need to run a database with minimal administrative effort. What's the recommended service? \n",
      "Response: Amazon RDS is the recommended service for running a fully-managed database with minimal administrative effort.\n",
      "Pattern: When should I purchase a zonal RI? \n",
      "Response: If you want to take advantage of the capacity reservation, then you should buy an RI in a specific AZ.\n",
      "Pattern: What's the recommended way to achieve high availability for my PostgreSQL database? \n",
      "Response: For high availability, use Amazon RDS Multi-AZ deployments. It automatically replicates your database to a standby instance in a different Availability Zone.\n",
      "Pattern: What happens during Multi-AZ failover and how long does it take? \n",
      "Response: Failover is automatically handled by Amazon RDS so that you can resume database operations as quickly as possible without administrative intervention. When failing over, Amazon RDS simply flips the canonical name record (CNAME) for your DB instance to point at the standby, which is in turn promoted to become the new primary. We encourage you to follow best practices and implement database connection retry at the application layer. Failovers, as defined by the interval between the detection of the failure on the primary and the resumption of transactions on the standby, typically complete within one to two minutes. Failover time can also be affected by whether large uncommitted transactions must be recovered; the use of adequately large instance types is recommended with Multi-AZ for best results. AWS also recommends the use of Provisioned IOPS with Multi-AZ instances, for fast, predictable, and consistent throughput performance. \n",
      "Pattern: How much VPC flow logs cost? \n",
      "Response: Data ingestion and archival charges for vended logs apply when you publish flow logs to CloudWatch Logs or to Amazon S3. For more information and examples, see Amazon CloudWatch Pricing. You can also track charges from publishing flow logs using cost allocation tags. \n",
      "Pattern: How are reserved instances different from on-demand DB instances? \n",
      "Response: Functionally, reserved instances and on-demand DB instances are exactly the same. The only difference is how your DB instance(s) are billed. With Reserved Instances, you purchase a one- or three-year reservation and in return receive a lower effective hourly usage rate (compared with on-demand DB instances) for the duration of the term. Unless you purchase reserved instances in a Region, all DB instances will be billed at on-demand hourly rates. \n",
      "Pattern: Do I need to configure my function with VPC settings before I can use my Amazon EFS file system? \n",
      "Response: Yes. Mount targets for Amazon EFS are associated with a subnet in a VPC. The AWS Lambda function needs to be configured to access that VPC. \n",
      "Pattern: In which Amazon EC2 Regions can I use VM Import/Export? \n",
      "Response: Visit the Region Table page to see product service availability by Region.\n",
      "Pattern: What is a High I/O instance? \n",
      "Response: High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for low latency networking.\n",
      "Pattern: Can I enable both Lambda SnapStart and PC on the same function? \n",
      "Response: No. Lambda SnapStart and PC cannot be enabled at the same time, on the same function. \n",
      "Pattern: Can I use packages with AWS Lambda? \n",
      "Response: Yes. You can use NPM packages as well as custom packages. Learn more here. \n",
      "Pattern: I need to run a database with minimal administrative effort. What's the recommended service? \n",
      "Response: Amazon RDS is the recommended service for running a fully-managed database with minimal administrative effort.\n",
      "Pattern: Can I enable hibernation on an existing instance? \n",
      "Response: No, you cannot enable hibernation on an existing instance (running or stopped). This needs to be enabled during instance launch.\n",
      "Pattern: How many EBS volumes and Elastic Network Interfaces (ENIs) can be attached to instances running on the Nitro Hypervisor? \n",
      "Response: Instances running on the Nitro Hypervisor support a maximum of 27 additional PCI devices for EBS volumes and VPC ENIs. Each EBS volume or VPC ENI uses a PCI device. For example, if you attach 3 additional network interfaces to an instance that uses the Nitro Hypervisor, you can attach up to 24 EBS volumes to that instance.\n",
      "Pattern: How can I resume a hibernating instance? \n",
      "Response: You can resume by calling the StartInstances API as you would for a regular stopped instance. You can also do this through the console by selecting your instance, then clicking Actions > Instance State > Start.\n",
      "Pattern: Do vCPU limits apply when purchasing Reserved Instances or requesting Spot Instances? \n",
      "Response: No, the vCPU-based limits only apply to running On-Demand instances and Spot Instances.\n",
      "Pattern: What happens if my Lambda function fails while processing an event? \n",
      "Response: On failure, Lambda functions being invoked synchronously will respond with an exception. Lambda functions being invoked asynchronously are retried at least 3 times. Events from Amazon Kinesis streams and Amazon DynamoDB streams are retried until the Lambda function succeeds or the data expires. Kinesis and DynamoDB Streams retain data for a minimum of 24 hours. \n",
      "Pattern: How can I communicate the AZ of an On-Demand Capacity Reservation with another account, given AZ name mappings could be different across AWS accounts? \n",
      "Response: You can now use an Availability Zone ID (AZ ID) instead of an AZ name. An AZ ID is a static reference and provides a consistent way of identifying the location of a resource across all your accounts. This makes it easier for you to provision resources centrally in a single account and share them across multiple accounts.\n",
      "Pattern: Who should use S3 Transfer Acceleration? \n",
      "Response: S3 Transfer Acceleration is designed to optimize transfer speeds from across the world into S3 buckets. If you are uploading to a centralized bucket from geographically dispersed locations or if you regularly transfer GBs or TBs of data across continents, you may save hours or days of data transfer time with S3 Transfer Acceleration.\n",
      "Pattern: How do I monitor an AWS Lambda function? \n",
      "Response: AWS Lambda automatically monitors Lambda functions on your behalf, reporting real-time metrics through Amazon CloudWatch, including total requests, account-level and function-level concurrency usage, latency, error rates, and throttled requests. You can view statistics for each of your Lambda functions via the Amazon CloudWatch console or through the AWS Lambda console. You can also call third-party monitoring APIs in your Lambda function.  Visit Troubleshooting CloudWatch metrics to learn more. Standard charges for AWS Lambda apply to use Lambda's built-in metrics. \n",
      "Pattern: Does Amazon RDS provide guidelines for support of new DB engine versions? \n",
      "Response: Over time, Amazon RDS adds support for new major and minor database engine versions. The number of new versions supported will vary based on the frequency and content of releases and patches from the engine's vendor or development organization and the outcome of a thorough vetting of these releases and patches by our database engineering team. However, as a general guidance, we aim to support new engine versions within 5 months of their general availability. \n",
      "Pattern: What workloads are suited for X2gd instances? \n",
      "Response: X2gd is ideal for customers with Arm-compatible memory bound scale-out workloads such as Redis and Memcached in-memory databases, that need low latency memory access and benefit from more memory per vCPU. X2gd is also well suited for relational databases such as PostgreSQL, MariaDB, MySQL, and RDS Aurora. Customers who run memory intensive workloads such as Apache Hadoop, real-time analytics, and real-time caching servers will benefit from 1:16 vCPU to memory ratio of X2gd. Single threaded workloads such as EDA backend verification jobs will benefit from physical core and more memory of X2gd instances, allowing them to consolidate more workloads on to a single instance. X2gd instance also feature local NVMe SSD block storage to improve response times by acting as a caching layer.\n",
      "Pattern: What does the AWS Free Tier for Amazon RDS offer? \n",
      "Response: The AWS Free Tier for Amazon RDS offer provides free use of Single-AZ Micro DB instances running MySQL, MariaDB, PostgreSQL, and SQL Server Express Edition. The free usage tier is capped at 750 instance hours per month. Customers also receive 20 GB of General Purpose (SSD) database storage and 20 GB of backup storage for free per month. \n",
      "Pattern: Can I automatically scale Amazon EC2 Auto Scaling Groups? \n",
      "Response: Yes. Amazon EC2 Auto Scaling is a fully managed service designed to launch or terminate Amazon EC2 instances automatically to help ensure you have the correct number of Amazon EC2 instances available to handle the load for your application. EC2 Auto Scaling helps you maintain application availability through fleet management for EC2 instances, which detects and replaces unhealthy instances, and by scaling your Amazon EC2 capacity up or down automatically according to conditions you define. You can use EC2 Auto Scaling to automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs.\n",
      "Pattern: I have a valid use case for sending emails to port 25 from EC2. How can I have these port 25 restrictions removed? \n",
      "Response: If you have a valid use case for sending emails to port 25 (SMTP) from EC2, please submit a Request to Remove Email Sending Limitations to have these restrictions lifted. You can alternately send emails using a different port, or leverage an existing authenticated email relay service such as Amazon Simple Email Service (Amazon SES).\n",
      "Pattern: What instances are supported? \n",
      "Response: ENA Express is supported on Graviton-, Intel-, and AMD-based EC2 instances. It is supported on compute-optimized, memory-optimized, general purpose and storage-optimized based instances. For a complete list of supported instances, please see the ENA Express user guide.\n",
      "Pattern: Can I create a read replica with a Multi-AZ DB instance deployment as its source? \n",
      "Response: Yes. Since Multi-AZ DB instances address a different need than read replicas, it makes sense to use the two in conjunction for production deployments and to associate a read replica with a Multi-AZ DB Instance deployment. The  source  Multi AZ-DB instance provides you with enhanced write availability and data durability, and the associated read replica would improve read traffic scalability. \n",
      "Pattern: Do you support multiple instances accessing a single volume? \n",
      "Response: Yes, you can enable Multi-Attach on an EBS Provisioned IOPS io1 volume to allow a volume to be concurrently attached to up to sixteen Nitro-based EC2 instances within the same Availability Zone. For more information on Amazon EBS Multi-Attach, see the EBS product page.\n",
      "Pattern: Can you walk me through a conversion between No Upfront Convertible RIs? \n",
      "Response: Unlike conversions between Convertible RIs with an upfront value, since you're converting between RIs without an upfront cost, there will not be a true-up charge. However, the amount you pay on an hourly basis before the exchange will need to be greater than or equal to the amount you pay on a total hourly basis after the exchange.\n",
      "Pattern: Do you support multiple instances accessing a single volume? \n",
      "Response: Yes, you can enable Multi-Attach on an EBS Provisioned IOPS io1 volume to allow a volume to be concurrently attached to up to sixteen Nitro-based EC2 instances within the same Availability Zone. For more information on Amazon EBS Multi-Attach, see the EBS product page.\n",
      "Pattern: When should I use Lambda@Edge? \n",
      "Response: Lambda@Edge is optimized for latency-sensitive use cases where your end viewers are distributed globally. All the information you need to make a decision should be available at the CloudFront edge, within the function and the request. This means that use cases where you are looking to make decisions on how to serve content based on user characteristics (e.g., location, client device, etc.) can now be executed and served close to your users without having to be routed back to a centralized server. \n",
      "Pattern: Are there any restrictions on the customers when purchasing third-party RIs? \n",
      "Response: Yes, you cannot purchase your own listed RIs, including those in any of your linked accounts (via Consolidated Billing).\n",
      "Pattern: How can I use Container Image Support for AWS Lambda? \n",
      "Response: You can start with either an AWS provided base images for Lambda or by using one of your preferred community or private enterprise images. Then, simply use Docker CLI to build the image, upload it to Amazon ECR, and then create the function by using all familiar Lambda interfaces and tools, such as the AWS Management Console, the AWS CLI, the AWS SDK, AWS SAM, and AWS CloudFormation. \n",
      "Pattern: Why should I use S3 Multi-Region Access Points? \n",
      "Response: S3 Multi-Region Access Points accelerate and simplify storage for your multi-region applications. By dynamically routing S3 requests made to a replicated data set, S3 Multi-Region Access Points reduce request latency, so that applications run up to 60% faster. S3 Multi-Region Access Points can also help you build resilient, multi-region and multi-account applications that are more protected against accidental or unauthorized data deletion. With S3 Multi-Region Access Points, you are able to take advantage of the global infrastructure of AWS while maintaining a simple region-agnostic architecture for your applications.\n",
      "Pattern: Will my DB instance remain available during scaling? \n",
      "Response: The storage capacity allocated to your DB Instance can be increased while maintaining DB Instance availability. However, when you decide to scale the compute resources available to your DB instance up or down, your database will be temporarily unavailable while the DB instance class is modified. This period of unavailability typically lasts only a few minutes, and will occur during the maintenance window for your DB Instance, unless you specify that the modification should be applied immediately. \n",
      "Pattern: Do Amazon RDS Blue/Green Deployments support Global Databases, Amazon RDS Proxy, cross-Region read replicas, or cascaded read replicas? \n",
      "Response: No, Amazon RDS Blue/Green Deployments do not support Global Databases, Amazon RDS Proxy, cross-Region read replicas, or cascaded read replicas. \n",
      "Pattern: Will all features and AMIs on my previous generation instances be supported as a part of this migration? \n",
      "Response: Yes, all existing features and AMIs supported on previous generation instances will be supported as we migrate these instances to AWS Nitro System.\n",
      "Pattern: Which instances and operating systems support hibernation? \n",
      "Response: Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.\n",
      "Pattern: How can I manage my AWS Lambda functions? \n",
      "Response: How can I manage my AWS Lambda functions? \n",
      "Pattern: What are the various storage options available on M6g instances? \n",
      "Response: M6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. M6g instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. Additionally, options with local NVMe instance storage are also available through the M6gd instance types.\n",
      "Pattern: Is there a limit on the number of Cluster Compute or Cluster GPU Instances I can use and/or the size of cluster I can create by launching Cluster Compute Instances or Cluster GPU into a cluster placement group? \n",
      "Response: There is no limit specific for Cluster Compute Instances. For Cluster GPU Instances, you can launch 2 Instances on your own. If you need more capacity, please complete the Amazon EC2 instance request form (selecting the appropriate primary instance type).\n",
      "Pattern: How can I use Amazon S3 Lifecycle management to help lower my Amazon S3 storage costs? \n",
      "Response: With Amazon S3 Lifecycle policies, you can configure your objects to be migrated from the S3 Standard storage class to S3 Standard-IA or S3 One Zone-IA and/or archived to S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, or S3 Glacier Deep Archive storage classes.   You can also specify an S3 Lifecycle policy to delete objects after a specific period of time. You can use this policy-driven automation to quickly and easily reduce storage costs as well as save time. In each rule you can specify a prefix, a time period, a transition to S3 Standard-IA, S3 One Zone-IA, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, S3 Glacier Deep Archive, and/or an expiration. For example, you could create a rule that archives into S3 Glacier Flexible Retrieval all objects with the common prefix logs/ 30 days from creation and expires these objects after 365 days from creation.   You can also create a separate rule that only expires all objects with the prefix backups/ 90 days from creation. S3 Lifecycle policies apply to both existing and new S3 objects, helping you optimize storage and maximize cost savings for all current data and any new data placed in S3 without time-consuming manual data review and migration.   Within a lifecycle rule, the prefix field identifies the objects subject to the rule. To apply the rule to an individual object, specify the key name. To apply the rule to a set of objects, specify their common prefix (e.g. logs/). You can specify a transition action to have your objects archived and an expiration action to have your objects removed. For time period, provide the creation date (e.g. January 31, 2015) or the number of days from creation date (e.g. 30 days) after which you want your objects to be archived or removed. You may create multiple rules for different prefixes.\n",
      "Pattern: How do I deploy and manage a serverless application? \n",
      "Response: You can deploy and manage your serverless applications using the AWS Serverless Application Model (AWS SAM). AWS SAM is a specification that prescribes the rules for expressing serverless applications on AWS. This specification aligns with the syntax used by AWS CloudFormation today and is supported natively within AWS CloudFormation as a set of resource types (referred to as serverless resources). These resources make it easier for AWS customers to use CloudFormation to configure and deploy serverless applications using existing CloudFormation APIs. \n",
      "Pattern: What are AWS Lambda functions powered by Graviton2 processors? \n",
      "Response: AWS Lambda allows you to run your functions on either x86-based or Arm-based processors. AWS Graviton2 processors are custom built by Amazon Web Services using 64-bit Arm Neoverse cores to deliver increased price performance for your cloud workloads. Customers get the same advantages of AWS Lambda, running code without provisioning or managing servers, automatic scaling, high availability, and only paying for the resources you consume. \n",
      "Pattern: What are the benefits of a default VPC? \n",
      "Response: When you launch resources in a default VPC, you can benefit from the advanced networking functionalities of Amazon VPC (EC2-VPC) with the ease of use of Amazon EC2 (EC2-Classic). You can enjoy features such as changing security group membership on the fly, security group egress filtering, multiple IP addresses, and multiple network interfaces without having to explicitly create a VPC and launch instances in the VPC. \n",
      "Pattern: What is a High I/O instance? \n",
      "Response: High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for low latency networking.\n",
      "Pattern: What is the IAM policy simulator and when should I use it? \n",
      "Response: The IAM policy simulator evaluates policies you choose and determines the effective permissions for each of the actions you specify. Use the policy simulator to test and troubleshoot identity-based and resource-based policies, IAM permissions boundaries, and SCPs. For more information, see Testing IAM policies with the IAM policy simulator.\n",
      "Pattern: Are Spot fleet requests guaranteed to be fulfilled? \n",
      "Response: No. Spot fleet requests allow you to place multiple Spot Instance requests simultaneously, and are subject to the same availability and prices as a single Spot Instance request. For example, if no resources are available for the instance types listed in your Spot Fleet request, we may be unable to fulfill your request partially or in full. We recommend that you to include all the possible instance types and availability zones that are suitable for your workloads in the Spot Fleet.\n",
      "Pattern: When should I choose Elastic Inference (EI) for inference vs Amazon EC2 Inf1 instances? \n",
      "Response: There are two cases where developers would choose EI over Inf1 instances: (1) if you need different CPU and memory sizes than what Inf1 offers, then you can use EI to attach acceleration to the EC2 instance with the right mix of CPU and memory for your application (2) if your performance requirements are significantly lower than what the smallest Inf1 instance provides, then using EI could be a more cost effective choice. For example, if you only need 5 TOPS, enough for processing up to 6 concurrent video streams, then using the smallest slice of EI with a C5.large instance could be up to 50% cheaper than using the smallest size of an Inf1 instance.\n",
      "Pattern: When should I use Savings Plans, EC2 RIs, and On-Demand Capacity Reservations? \n",
      "Response: Use Savings Plans or Regional RIs to reduce your bill while committing to a one- or three-year term. Savings Plans offer significant savings over On-Demand, just like EC2 RIs, but automatically reduce customers' bills on compute usage across any AWS Region, even as usage changes. Use On-Demand Capacity Reservations if you need the additional confidence in your ability to launch instances. On-Demand Capacity Reservations can be created for any duration and can be managed independently of your Savings Plans or RIs. If you have Savings Plans or Regional RIs, they will automatically apply to matching On-Demand Capacity Reservations. This gives you the flexibility to selectively add On-Demand Capacity Reservations to a portion of your instance footprint and still reduce your bill for that usage.\n",
      "Pattern: How much of my RI term can I list? \n",
      "Response: You can sell an RI for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term RI.\n",
      "Pattern: What information can I view on the Amazon RDS dashboard? \n",
      "Response: You can view all the system metrics and process information for your Amazon RDS DB Instances in a graphical format on the console. You can manage which metrics you want to monitor for each instance and customize the dashboard according to your requirements. \n",
      "Pattern: What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates? \n",
      "Response: Metrics are received and aggregated at 1 minute intervals.\n",
      "Pattern: How do you release a Dedicated Host? \n",
      "Response: The minimum allocation period for an EC2 Mac instance Dedicated Host is 24 hours. After the allocation period has exceeded 24 hours, first stop or terminate the instance running on the host, then release the host using the aws ec2 release-hosts CLI command or the AWS Management Console.\n",
      "Pattern: How can I use the processor state control feature available on the c4.8xlarge instance? \n",
      "Response: The c4.8xlarge instance type provides the ability for an operating system to control processor C-states and P-states. This feature is currently available only on Linux instances. You may want to change C-state or P-state settings to increase processor performance consistency, reduce latency, or tune your instance for a specific workload. By default, Amazon Linux provides the highest-performance configuration that is optimal for most customer workloads; however, if your application would benefit from lower latency at the cost of higher single- or dual-core frequencies, or from lower-frequency sustained performance as opposed to bursty Turbo Boost frequencies, then you should consider experimenting with the C-state or P-state configuration options that are available to these instances. For additional information on this feature, see the Amazon EC2 User Guide section on Processor State Control.\n",
      "Pattern: What AWS documentation supports the SEC 17a-4(f)(2)(i) and CFTC 1.31(c) requirement for notifying my regulator? \n",
      "Response: Provide notification to your regulator or Designated Examining Authority (DEA) of your choice to use Amazon S3 for electronic storage along with a copy of the Cohasset Assessment. For the purposes of these requirements, AWS is not a designated third party (D3P). Be sure to select a D3P and include this information in your notification to your DEA.\n",
      "Pattern: What types of identity are supported for S3 Access Grants permission grants? \n",
      "Response: S3 Access Grants supports two kinds of identities: enterprise user or group identities from AWS Identity Center, and AWS IAM principals including IAM users and roles. When you use S3 Access Grants with AWS Identity Center, you can define data permissions on the basis of directory group memberships. AWS Identity Center is an AWS service that connects to commonly-used identity providers, including Entra ID, Okta, Ping, and others. In addition to supporting directory identities via AWS Identity Center, S3 Access Grants also supports permission rules for AWS IAM principal including IAM users and roles. This is for use cases where you either manage a custom identity federation not through AWS Identity Center but via IAM and SAML assertion (example implementation), or manage application identities based on IAM principals, and still would like to use S3 Access Grants due to its scalability and auditability.\n",
      "Pattern: What is Code Signing for AWS Lambda? \n",
      "Response: Code Signing for AWS Lambda offers trust and integrity controls that enable you to verify that only unaltered code from approved developers is deployed in your Lambda functions. You can use AWS Signer, a fully-managed code signing service, to digitally sign code artifacts and configure your Lambda functions to verify the signatures at deployment. Code Signing for AWS Lambda is currently only available for functions packaged as ZIP archives. \n",
      "Pattern: How can I manage my AWS Lambda functions? \n",
      "Response: How can I manage my AWS Lambda functions? \n",
      "Pattern: When should I use ENA Express? \n",
      "Response: ENA Express works best for applications requiring high, single-flow throughput, like distributed storage systems and live media encoding. These workloads require high single flow bandwidth and low tail latency.\n",
      "Pattern: What is the pricing of AWS Lambda functions powered by AWS Graviton2 processors? Does the AWS Lambda free tier apply to functions powered by Graviton2? \n",
      "Response: AWS Lambda functions powered by AWS Graviton2 processors are 20% cheaper compared to x86-based Lambda functions. The Lambda free tier applies to AWS Lambda functions powered by x86 and Arm-based architectures. \n",
      "Pattern: What are Amazon EC2 T4g instances? \n",
      "Response: Amazon EC2 T4g instances are the next-generation of general purpose burstable instances powered by Arm-based AWS Graviton2 processors. T4g instances deliver up to 40% better price performance over T3 instances. They are built on the AWS Nitro System, a combination of dedicated hardware and Nitro hypervisor.\n",
      "Pattern: Can I update my Kubernetes cluster to a new version? \n",
      "Response: Yes. Amazon EKS performs managed, in-place cluster upgrades for both Kubernetes and Amazon EKS platform versions. This simplifies cluster operations and lets you take advantage of the latest Kubernetes features, as well as the updates to Amazon EKS configuration and security patches.\n",
      "Pattern: With such high durability, do I still need to back up my critical data? \n",
      "Response: Yes. Amazon S3's durability system does not protect against accidental or malicious deletes. S3 relies on customers to decide what data they want to keep, what data they want to get rid of, and what optional controls they need to protect against deletes that are incorrect, either due to accidents or malice. When you tell Amazon S3 to delete data, that data is immediately deleted, and it cannot be recovered by AWS. Honoring a delete request in this way is an important characteristic of the service.\n",
      "Pattern: Can I tag a Spot Fleet request? \n",
      "Response: You can request to launch Spot Instances with tags via Spot Fleet. The Fleet by itself cannot be tagged.\n",
      "Pattern: How do I use Lambda@Edge? \n",
      "Response: To use Lambda@Edge, you just upload your code to AWS Lambda and associate a function version to be triggered in response to Amazon CloudFront requests. Your code must satisfy the Lambda@Edge service limits. Lambda@Edge supports Node.js and Python for global invocation by CloudFront events at this time. Learn more in our documentation. \n",
      "Pattern: How do I enable Amazon S3 Object Lock on a bucket? \n",
      "Response: You can use the Amazon S3 console, AWS API, or AWS CLI to enable S3 Object Lock while creating a new bucket or to configure S3 Object Lock on existing buckets. To enable S3 Object Lock on existing buckets, you can use the Amazon S3 console to edit S3 Object Lock settings in the bucket Properties tab the PutObjectLockConfiguration AWS API, or the AWS CLI. Once S3 Object Lock is enabled, you can set a default bucket level retention mode and time that will be applicable to all new objects uploaded to the bucket. For more information see the documentation on configuring S3 Object Lock using the S3 console, using the AWS API, and using the AWS CLI.\n",
      "Pattern: Which operating systems/AMIs are supported on X2gd instances? \n",
      "Response: The following AMIs are supported: Amazon Linux 2, Ubuntu 18.04 or newer, Red Hat Enterprise Linux 8.2 or newer, and SUSE Enterprise Server 15 or newer. Customers will find additional AMIs such as Fedora, Debian, NetBSD, and CentOS available through community AMIs and the AWS Marketplace. For containerized applications, Amazon ECS and EKS optimized AMIs are available as well.\n",
      "Pattern: What is AWS Fargate? \n",
      "Response: AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). AWS Fargate makes it easy to focus on building your applications by eliminating the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design. \n",
      "Pattern: Why can I not create a particular version? \n",
      "Response: In some cases, we may deprecate specific major or minor versions without prior notice, such as when we discover a version does not meet our high quality, performance, or security bar. In the unlikely event that such cases occur, Amazon RDS will discontinue the creation of new database instances and clusters with these versions. Existing customers may continue to be able to run their databases. Specific circumstances may dictate different timelines depending on the issue being addressed. \n",
      "Pattern: What are the various storage options available to A1 customers? \n",
      "Response: A1 instances are EBS-optimized by default and offer up to 3,500 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. A1 instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. A1 instances will not support the blkfront interface.\n",
      "Pattern: After failover, my primary is now located in a different Availability Zone than my other AWS resources (e.g. EC2 instances). Should I be concerned about latency? \n",
      "Response: Availability Zones are engineered to provide low latency network connectivity to other Availability Zones in the same Region. In addition, you may want to consider architecting your application and other AWS resources with redundancy across multiple Availability Zones so your application will be resilient in the event of an Availability Zone failure. Multi-AZ deployments address this need for the database tier without administration on your part. \n",
      "Pattern: Can I move my existing DB instances outside VPC into my VPC? \n",
      "Response: If your DB instance is not in a VPC, you can use the AWS Management Console to easily move your DB instance into a VPC. See the Amazon RDS User Guide for more details. You can also take a snapshot of your DB Instance outside VPC and restore it to VPC by specifying the DB Subnet Group you want to use. Alternatively, you can perform a  Restore to Point in Time  operation as well. \n",
      "Pattern: What is S3 Transfer Acceleration? \n",
      "Response: Amazon S3 Transfer Acceleration creates fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. S3 Transfer Acceleration leverages Amazon CloudFront's globally distributed AWS Edge locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.\n",
      "Pattern: How do I configure my Lambda functions to enable code signing? \n",
      "Response: You can enable code signing by creating a Code Signing Configuration through the AWS Management Console, the Lambda API, the AWS CLI, AWS CloudFormation, and AWS SAM. Code Signing Configuration helps you specify the approved signing profiles and configure whether to warn or reject deployments if signature checks fail. Code Signing Configurations can be attached to individual Lambda functions to enable the code signing feature. Such functions now start verifying signatures at deployment. \n",
      "Pattern: What is a Cluster Compute Instance? \n",
      "Response: Cluster Compute Instances combine high compute resources with high performance networking for HPC applications and other demanding network-bound applications. Cluster Compute Instances provide similar functionality to other Amazon EC2 instances but have been specifically engineered to provide high performance networking.\n",
      "Pattern: Does AWS provide a developer kit? \n",
      "Response: Yes. The Hardware Development Kit (HDK) includes simulation tools and simulation models for developers to simulate, debug, build, and register their acceleration code. The HDK includes code samples, compile scripts, debug interfaces, and many other tools you will need to develop the FPGA code for your F1 instances. You can use the HDK either in an AWS provided AMI, or in your on-premises development environment. These models and scripts are available, publicly with an AWS account.\n",
      "Pattern: What is Optimize CPUs? \n",
      "Response: Optimize CPUs gives you greater control of your EC2 instances on two fronts. First, you can specify a custom number of vCPUs when launching new instances to save on vCPU-based licensing costs. Second, you can disable Intel Hyper-Threading Technology (Intel HT Technology) for workloads that perform well with single-threaded CPUs, such as certain HPC applications.\n",
      "Pattern: What happens if my function fails while processing an event? \n",
      "Response: For Amazon S3 bucket notifications and custom events, AWS Lambda will attempt execution of your function three times in the event of an error condition in your code or if you exceed a service or resource limit. For ordered event sources that AWS Lambda polls on your behalf, such as Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution in the event of a developer code error until the data expires. You can monitor progress through the Amazon Kinesis and Amazon DynamoDB consoles and through the Amazon CloudWatch metrics that AWS Lambda generates for your function. You can also set Amazon CloudWatch alarms based on error or execution throttling rates. \n",
      "Pattern: What are IAM Access Analyzer custom policy checks? \n",
      "Response: IAM Access Analyzer custom policy checks validate that IAM policies adhere to your security standards ahead of deployments. Custom policy checks use the power of automated reasoning provable security assurance backed by mathematical proof  to enable security teams to proactively detect nonconformant updates to policies. For example, IAM policy changes that are more permissive than their previous version. Security teams can use these checks to streamline their reviews, automatically approving policies that conform with their security standards, and inspecting more deeply when they don't. This new kind of validation provides higher security assurance in the cloud. Security and development teams can automate policy reviews at scale by integrating these custom policy checks into the tools and environments where developers author their policies, such as their CI/CD pipelines.\n",
      "Pattern: How can I get started with Amazon EC2? \n",
      "Response: To sign up for Amazon EC2, select the Sign up for This Web Service button on the Amazon EC2 detail page. You must have an AWS account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 signup process. After signing up, please refer to the Amazon EC2 documentation, which includes our Getting Started Guide.\n",
      "Pattern: Can I get a discount for On-Demand Capacity Reservation usage? \n",
      "Response: Yes. Savings Plans or Regional RI discounts apply to On-Demand Capacity Reservations. AWS Billing automatically applies the discount when the attributes of an On-Demand Capacity Reservation match the attributes of a Savings Plan or Regional RI. When an On-Demand Capacity Reservation is used by an instance, you are only charged for the instance (with Savings Plan or RI discounts applied). Discounts are preferentially applied to instance usage before covering unused On-Demand Capacity Reservations.\n",
      "Pattern: How do I create a DB instance? \n",
      "Response: DB instances are simple to create using either the AWS Management Console, Amazon RDS APIs, or AWS Command Line Interface. To launch a DB instance using the AWS Management Console, click RDS and then the  Launch DB Instance  button on the Instances tab. From there, you can specify the parameters for your DB instance, including DB engine and version, license model, instance type, storage type and amount, and primary user credentials. You also have the ability to change your DB instance's backup retention policy, preferred backup window, and scheduled maintenance window. Alternatively, you can create your DB instance using the CreateDBInstance API or create-db-instance command. \n",
      "Pattern: How do I control which Amazon S3 buckets can call which AWS Lambda functions? \n",
      "Response: When you configure an Amazon S3 bucket to send messages to an AWS Lambda function, a resource policy rule will be created that grants access. Visit the Lambda Developer Guide to learn more about resource policies and access controls for Lambda functions. \n",
      "Pattern: What are the different access levels that S3 Access Grants offers? \n",
      "Response: S3 Access Grants offers three access levels: READ, WRITE, and READWRITE. READ allows you to view and retrieve objects from S3. WRITE allows you to write to and delete from S3. READWRITE allows you to do both READ and WRITE.\n",
      "Pattern: How do I configure my application to use AWS Lambda ephemeral storage? \n",
      "Response: You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update. \n",
      "Pattern: I have a variable workload with unpredictable traffic. How can I optimize costs for my database? \n",
      "Response: Consider using Amazon RDS On-Demand Instances for flexibility or Amazon RDS Aurora Serverless for automatic cost optimization based on actual usage.\n",
      "Pattern: Why should I use Amazon EKS add-ons? \n",
      "Response: Amazon EKS add-ons provides one-click installation and management of Kubernetes operational software. Go from cluster creation to running applications in a single command, while easily keeping the operational software required for your cluster up to date. This ensures your Kubernetes clusters are secure and stable and reduces the amount of work needed to start and manage production-ready Kubernetes clusters on AWS.\n",
      "Pattern: Which storage interface is supported on C5 instances? \n",
      "Response: C5 instances will support only NVMe EBS device model. EBS volumes attached to C5 instances will appear as NVMe devices. NVMe is a modern storage interface that provides latency reduction and results in increased disk I/O and throughput.\n",
      "Pattern: What are traditional risks of running extensions in PostgreSQL and how does TLE for PostgreSQL mitigate those risks? \n",
      "Response: PostgreSQL extensions are executed in the same process space for high performance. However, extensions might have software defects that can crash the database.  TLE for PostgreSQL offers multiple layers of protection to mitigate this risk. TLE is designed to limit access to system resources. The rds_superuser role can determine who is permitted to install specific extensions. However, these changes can only be made through the TLE API. TLE is designed to limit the impact of an extension defect to a single database connection. In addition to these safeguards, TLE is designed to provide DBAs in the rds_superuser role fine-grained, online control over who can install extensions and they can create a permissions model for running them.  Only users with sufficient privileges will be able to run and create using the  CREATE EXTENSION  command on a TLE extension. DBAs can also allow-list  PostgreSQL hooks  required for more sophisticated extensions that modify the database's internal behavior and typically require elevated privilege. \n",
      "Pattern: Data Requests: \n",
      "Response: Amazon S3 Request pricing is summarized on the Amazon S3 pricing page.\n",
      "Pattern: What is VM Import/Export? \n",
      "Response: VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.\n",
      "Pattern: Will vCPU limits be available in all Regions? \n",
      "Response: vCPU-based instance limits are available in all commercial AWS Regions.\n",
      "Pattern: How can I ensure my instances are always available even during unexpected interruptions? \n",
      "Response: Use a mix of On-Demand and Spot Instances with Auto Scaling. Auto Scaling can automatically replace Spot Instances that are interrupted, ensuring your application remains available.\n",
      "Pattern: How do I decide which AWS Region to store my data in? \n",
      "Response: There are several factors to consider based on your specific application. For instance, you may want to store your data in a Region that is near your customers, your data centers, or other AWS resources to reduce data access latencies. You may also want to store your data in a Region that is remote from your other operations for geographic redundancy and disaster recovery purposes. You should also consider Regions that let you address specific legal and regulatory requirements and/or reduce your storage costs you can choose a lower priced Region to save money. For S3 pricing information, visit the Amazon S3 pricing page.\n",
      "Pattern: How do switchovers work with Amazon RDS Blue/Green Deployments? \n",
      "Response: When Amazon RDS Blue/Green Deployments initiate a switchover, they block writes to both the blue and green environments, until switchover is complete. During switchover, the staging environment, or green environment, catches up with the production system, ensuring data is consistent between the staging and production environment. Once the production and staging environment are in complete sync, Blue/Green Deployments promote the staging environment as the production environment by redirecting traffic to the newly promoted production environment. Blue/Green Deployments are designed to enable writes on the green environment after switchover is complete, ensuring zero data loss during the switchover process. \n",
      "Pattern: What is the difference between hibernate and stop? \n",
      "Response: In the case of hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shut down and RAM is cleared.\n",
      "Pattern: How do I access a file system from an Amazon EC2 instance? \n",
      "Response: To access your file system, you mount the file system on an Amazon EC2 Linux-based instance using the standard Linux mount command and the file system's DNS name. Once you've mounted, you can work with the files and directories in your file system just like you would with a local file system.\n",
      "Pattern: What is an AWS Lambda function? \n",
      "Response: The code you run on AWS Lambda is uploaded as a Lambda function. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a stateless style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones. \n",
      "Pattern: How does AWS Lambda isolate my code? \n",
      "Response: Each AWS Lambda function runs in its own isolated environment, with its own resources and file system view. AWS Lambda uses the same techniques as Amazon EC2 to provide security and separation at the infrastructure and execution levels. \n",
      "Pattern: Is AWS Lambda ephemeral storage encrypted? \n",
      "Response: Yes. All data stored in ephemeral storage is encrypted at rest with a key managed by AWS. \n",
      "Pattern: What kind of code can run on AWS Lambda? \n",
      "Response: AWS Lambda offers an easy way to accomplish many activities in the cloud. For example, you can use AWS Lambda to build mobile back-ends that retrieve and transform data from Amazon DynamoDB, handlers that compress or transform objects as they are uploaded to Amazon S3, auditing and reporting of API calls made to any Amazon Web Service, and server-less processing of streaming data using Amazon Kinesis. \n",
      "Pattern: What does it cost to use Amazon S3 Event Notifications? \n",
      "Response: There are no additional charges for using Amazon S3 for event notifications. You pay only for use of Amazon SNS or Amazon SQS to deliver event notifications, or for the cost of running an AWS Lambda function. Visit the Amazon SNS, Amazon SQS, or AWS Lambda pricing pages to view the pricing details for these services.\n",
      "Pattern: Do A1 instances support the AWS Nitro System? \n",
      "Response: Yes, A1 instances are powered by the AWS Nitro System, a combination of dedicated hardware and Nitro hypervisor.\n",
      "Pattern: What price will I pay for a Spot Instance? \n",
      "Response: You pay the Spot price that's in effect at the beginning of each instance-hour for your running instance. If Spot price changes after you launch the instance, the new price is charged against the instance usage for the subsequent hour.\n",
      "Pattern: What is Container Image Support for AWS Lambda? \n",
      "Response: AWS Lambda now enables you to package and deploy functions as container images. Customers can leverage the flexibility and familiarity of container tooling, and the agility and operational simplicity of AWS Lambda to build applications. \n",
      "Pattern: What is AWS Identity and Access Management (IAM)? \n",
      "Response: IAM provides fine-grained access control across all of AWS. With IAM, you can control access to services and resources under specific conditions. Use IAM policies to manage permissions for your workforce and systems to ensure least privilege. IAM is offered at no additional charge. For more information, see What is IAM?\n",
      "Pattern: How do RIs work with Consolidated Billing? \n",
      "Response: Our system automatically optimizes which instances are charged at the discounted rate to ensure that the consolidated accounts always pay the lowest amount. If you own RIs that apply to an AZ, then only the account which owns the RI will receive the capacity reservation. However, the discount will automatically apply to usage in any account across your consolidated billing family.\n",
      "Pattern: Will there be more compute choices offered with the C6 instance families? \n",
      "Response: Yes, we plan to offer Intel and AMD CPU powered instances in the future as part of the C6 instance families.\n",
      "Pattern: Do you offer encryption on Amazon EBS volumes and snapshots? \n",
      "Response: Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements.\n",
      "Pattern: Do volumes need to be un-mounted in order to take a snapshot? Does the snapshot need to complete before the volume can be used again? \n",
      "Response: No, snapshots can be done in real time while the volume is attached and in use. However, snapshots only capture data that has been written to your Amazon EBS volume, which might exclude any data that has been locally cached by your application or OS. In order to ensure consistent snapshots on volumes attached to an instance, we recommend cleanly detaching the volume, issuing the snapshot command, and then reattaching the volume. For Amazon EBS volumes that serve as root devices, we recommend shutting down the machine to take a clean snapshot.\n",
      "Pattern: How much data can I store in Amazon S3? \n",
      "Response: The total volume of data and number of objects you can store in Amazon S3 are unlimited. Individual Amazon S3 objects can range in size from a minimum of 0 bytes to a maximum of 5 TB. The largest object that can be uploaded in a single PUT is 5 GB. For objects larger than 100 MB, customers should consider using the multipart upload capability.\n",
      "Pattern: Can I use Spot Fleet with Elastic Load Balancing, Auto Scaling, or Elastic MapReduce? \n",
      "Response: You can use Auto Scaling features with Spot Fleet such as target tracking, health checks, CloudWatch metrics, etc., and can attach instances to your Elastic load balancers (both classic and application load balancers). Elastic MapReduce has a feature named Instance fleets that provides capabilities similar to Spot Fleet.\n",
      "Pattern: How can I get started with Amazon EC2? \n",
      "Response: To sign up for Amazon EC2, select the Sign up for This Web Service button on the Amazon EC2 detail page. You must have an AWS account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 signup process. After signing up, please refer to the Amazon EC2 documentation, which includes our Getting Started Guide.\n",
      "Pattern: Are Spot blocks (Fixed Duration Spot instances) ever interrupted? \n",
      "Response: Spot blocks are designed not to be interrupted and will run continuously for the duration you select, independent of Spot market price. In rare situations, Spot blocks may be interrupted due to AWS capacity needs. In these cases, we will provide a two-minute warning before we terminate your instance (termination notice), and you will not be charged for the affected instance(s).\n",
      "Pattern: What happens if my function fails while processing an event? \n",
      "Response: For Amazon S3 bucket notifications and custom events, AWS Lambda will attempt execution of your function three times in the event of an error condition in your code or if you exceed a service or resource limit. For ordered event sources that AWS Lambda polls on your behalf, such as Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution in the event of a developer code error until the data expires. You can monitor progress through the Amazon Kinesis and Amazon DynamoDB consoles and through the Amazon CloudWatch metrics that AWS Lambda generates for your function. You can also set Amazon CloudWatch alarms based on error or execution throttling rates. \n",
      "Pattern: Will I incur any data transfer out to the internet charges when I move my data out of AWS? \n",
      "Response: AWS offers eligible customers free data transfer out to the internet when they move all of their data off of AWS, in accordance with the process below.\n",
      "Pattern: What size options are available with EC2 Capacity Blocks? \n",
      "Response: EC2 Capacity Blocks are available in cluster sizes of 1, 2, 4, 8, 16, 32, and 64 instances, and they can be reserved for up to 14 days in one-day multiples.\n",
      "Pattern: Do I need to enable automatic backups on my DB instance before I can create read replicas? \n",
      "Response: Yes. Enable automatic backups on your source DB Instance before adding read replicas by setting the backup retention period to a value other than 0. Backups must remain enabled for read replicas to work. \n",
      "Pattern: What is AWS Lambda Provisioned Concurrency? \n",
      "Response: Provisioned Concurrency gives you greater control over the performance of your serverless applications. When enabled, Provisioned Concurrency keeps functions initialized and hyper-ready to respond in double-digit milliseconds. \n",
      "Pattern: How do I allow my AWS Lambda function access to other AWS resources? \n",
      "Response: You grant permissions to your Lambda function to access other resources using an IAM role. AWS Lambda assumes the role while executing your Lambda function, so you always retain full, secure control of exactly which AWS resources it can use. Visit Setting up AWS Lambda to learn more about roles. \n",
      "Pattern: What is Amazon S3? \n",
      "Response: Amazon S3 is object storage built to store and retrieve any amount of data from anywhere. S3 is a simple storage service that offers industry leading durability, availability, performance, security, and virtually unlimited scalability at very low costs.\n",
      "Pattern: How can you run older versions of macOS on EC2 Mac instances? \n",
      "Response: EC2 Mac instances are bare metal instances and do not use the Nitro hypervisor. You can install and run a type-2 virtualization layer on x86-based EC2 Mac instances to get access to macOS High Sierra, Sierra, or older macOS versions. On EC2 M1 Mac instances, as macOS Big Sur is the first macOS version to support Apple Silicon, older macOS versions will not run even under virtualization.\n",
      "Pattern: What is the difference between S3 Storage Lens and S3 Storage Class Analysis (SCA)? \n",
      "Response: S3 Storage Class Analysis provides recommendations for an optimal storage class by creating object age groups based on object-level access pattern within an individual bucket/prefix/tag for the previous 30-90 days. S3 Storage Lens provides daily organization level recommendations on ways to improve cost efficiency and apply data protection best practices, with additional granular recommendations by account, region, storage class, bucket, S3 Storage Lens group, or prefix (available with S3 Storage Lens advanced metrics). You can also use custom filters with S3 Storage Lens groups to visualize your storage based on object age and inform your storage archival strategy.\n",
      "Pattern: Will I incur any data transfer out to the internet charges when I move my data out of AWS? \n",
      "Response: AWS offers eligible customers free data transfer out to the internet when they move all of their data off of AWS, in accordance with the process below.\n",
      "Pattern: How many reserved instances can I purchase? \n",
      "Response: You can purchase up to 40 reserved DB instances. If you wish to run more than 40 DB instances, please complete the Amazon RDS DB Instance request form. \n",
      "Pattern: I want to grant different levels of access to different folders within my S3 bucket. How can I achieve this? \n",
      "Response: Use S3 bucket policies and IAM policies to define fine-grained access control for different folders within your S3 bucket.\n",
      "Pattern: When should I use X2gd instances compared to the X1, X2i, or R instances? \n",
      "Response: X2gd instances are suitable for Arm-compatible memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers. X2gd instances offer customers the lowest cost per gigabyte of memory within EC2, with sizes up to 1 TiB. X2iezn, X2idn, X2iedn, X1, and X1e instances use x86 processors and are suitable for memory-intensive enterprise-class, scale-up workloads such as Windows workloads, in-memory databases (e.g. SAP HANA), and relational databases (e.g. OracleDB). Customers can leverage the x86-based X instances for larger memory sizes up to 4 TiB. R6g and R6gd instances are suitable for workloads such as web applications, databases, and search indexing queries that need more vCPUs during times of heavy data processing. Customers running memory bound workloads that need less than 1 TiB memory and have dependency on x86 instruction set such as Windows applications, and applications like Oracle or SAP can leverage R5 instances and R6 instances.\n",
      "Pattern: What's the best way to get started with virtual servers on AWS? \n",
      "Response: Start with Amazon EC2. It offers a wide range of pre-configured Amazon Machine Images (AMIs), making it easy to launch instances with different operating systems and software stacks.\n",
      "Pattern: How am I billed when my instance-hour usage exceeds the Free Tier benefit? \n",
      "Response: You are billed at standard Amazon RDS prices for instance hours beyond what the Free Tier provides. See the Amazon RDS pricing page for details. \n",
      "Pattern: How can AWS Fargate be extended through integrations with other systems? \n",
      "Response: AWS Fargate offers a flexible integration model inclusive of both first party AWS services and third party Amazon Partner Network (APN) solutions. The common integration mechanism is to run a sidecar container within a AWS Fargate task that can interact with the primary application container, for example a runtime security agent or log router that interacts with the primary application and then ships data to a centralized system for analysis and review. \n",
      "Pattern: Do you offer encryption on Amazon EBS volumes and snapshots? \n",
      "Response: Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements.\n",
      "Pattern: How do I select the right instance type? \n",
      "Response: Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance or burstable performance; Compute Optimized instances have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerated Computing instances use hardware accelerators, or co-processors, to perform functions such as floating point number calculations, graphics processing, or data pattern matching, more efficiently than is possible in software running on CPUs; Storage Optimized Instances provide low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, as well as dense HDD-storage instances, which provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size.\n",
      "Pattern: Do I need to enable automatic backups on my DB instance before I can create read replicas? \n",
      "Response: Yes. Enable automatic backups on your source DB Instance before adding read replicas by setting the backup retention period to a value other than 0. Backups must remain enabled for read replicas to work. \n",
      "Pattern: Can I specify a different AMI for each instance type that I want to use? \n",
      "Response: Yes, simply specify the AMI you'd like to use in each launch specification you provide in your Spot Fleet request.\n",
      "Pattern: How are G3 instances different from P2 instances? \n",
      "Response: G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.\n",
      "Pattern: How much of my RI term can I list? \n",
      "Response: You can sell an RI for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term RI.\n",
      "Pattern: What is Amazon EKS extended support? \n",
      "Response: Amazon EKS extended support for Kubernetes versions lets you use a Kubernetes minor version for up to 26 months from the time the version is generally available from Amazon EKS. Amazon EKS versions in extended support receive ongoing security patches for the Kubernetes control plane managed by Amazon EKS. Additionally, Amazon EKS will release critical patches for the Amazon VPC CNI, kube-proxy, and CoreDNS add-ons, AWS-published EKS Optimized Amazon Machine Images (AMIs) for Amazon Linux, Bottlerocket, Windows, and EKS Fargate nodes. AWS backs all Amazon EKS versions in both standard and extended support with full technical support. Extended support for Kubernetes versions is available in all AWS Regions where Amazon EKS is available, including AWS GovCloud (US) Regions. Learn more about the Amazon EKS version support policy in the Amazon EKS documentation.\n",
      "Pattern: What is a maintenance window? Will my DB instance be available during maintenance events? \n",
      "Response: The Amazon RDS maintenance window is your opportunity to control when DB instance modifications, database engine version upgrades, and software patching occurs, in the event they are requested or required. If a maintenance event is scheduled for a given week, it will be initiated during the maintenance window you identify. Maintenance events that require Amazon RDS to take your DB instance offline are scale compute operations (which generally take only a few minutes from start-to-finish), database engine version upgrades, and required software patching. Required software patching is automatically scheduled only for patches that are security and durability related. Such patching occurs infrequently (typically once every few months) and should seldom require more than a fraction of your maintenance window. If you do not specify a preferred weekly maintenance window when creating your DB instance, a 30-minute default value is assigned. If you wish to modify when maintenance is performed on your behalf, you can do so by modifying your DB instance in the AWS Management Console, the ModifyDBInstance API, or the modify-db-instance command. Each of your DB instances can have different preferred maintenance windows, if you so choose. Running your DB instance as a Multi-AZ deployment can further reduce the impact of a maintenance event. Please refer to the Amazon RDS User Guide for more information on maintenance operations. \n",
      "Pattern: What are some key use cases of P3 instances? \n",
      "Response: P3 instances use GPUs to accelerate numerous deep learning systems and applications including autonomous vehicle platforms, speech, image, and text recognition systems, intelligent video analytics, molecular simulations, drug discovery, disease diagnosis, weather forecasting, big data analytics, financial modeling, robotics, factory automation, real-time language translation, online search optimizations, and personalized user recommendations, to name just a few.\n",
      "Pattern: Can I initiate a  forced failover  for my Multi-AZ DB instance deployment? \n",
      "Response: Amazon RDS will automatically failover without user intervention under a variety of failure conditions. In addition, Amazon RDS provides an option to initiate a failover when rebooting your instance. You can access this feature via the AWS Management Console or when using the RebootDBInstance API call. \n",
      "Pattern: How do you connect to an EC2 Mac instance over SSH? \n",
      "Response: After launching your instance and receiving an instance id, you can use the following command to poll the instance and determine when it is ready for SSH access. Connecting over SSH to EC2 Mac instances follows the same process as connecting to other EC2 instances, such as those running Linux or Windows. To support connecting to your instance using SSH, launch the instance using a key pair and a security group that allows SSH access. Provide the .pem file for the key pair when you connect to the instance. For more information, please see the documentation.\n",
      "Pattern: What are some of the ideal use cases for C6g instances? \n",
      "Response: C6g instances deliver significant price performance benefits for compute-intensive workloads such as high performance computing (HPC), batch processing, ad serving, video encoding, gaming, scientific modelling, distributed analytics, and CPU-based machine learning inference. Customers deploying applications built on open source software across C instances family will find the C6g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation.\n",
      "Pattern: When should I purchase a zonal RI? \n",
      "Response: If you want to take advantage of the capacity reservation, then you should buy an RI in a specific AZ.\n",
      "Pattern: How do I configure my application to use AWS Lambda ephemeral storage? \n",
      "Response: You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update. \n",
      "Pattern: What are EC2 UltraClusters and how can I get access? \n",
      "Response: P4d instances are deployed in hyperscale clusters called EC2 UltraClusters. Each EC2 UltraCluster is comprised of more than 4,000 NVIDIA A100 Tensor Core GPUs, Petabit-scale networking, and scalable low latency storage with FSx for Lustre. Each EC2 UltraCluster is one of the world's top supercomputers. Anyone can easily spin up P4d instances in EC2 SuperClusters. For additional help, contact us.\n",
      "Pattern: What metrics can I use to monitor my AWS Lambda ephemeral storage usage? \n",
      "Response: You can use AWS CloudWatch Lambda Insight metrics to monitor your ephemeral storage usage. To learn more, see the AWS CloudWatch Lambda Insights documentation. \n",
      "Pattern: Is there a time limit for how long my code initialization can run with Lambda SnapStart? \n",
      "Response: The maximum allowed initialization duration for Lambda SnapStart will match the execution timeout duration you have configured for your function. The maximum configurable execution timeout limit for a function is 15 minutes. \n",
      "Pattern: How is Amazon S3 designed for 99.999999999% durability? \n",
      "Response: Amazon S3's designed for durability is a function of storage device failure rates and the rate at which S3 can detect failure, and then re-replicate data on those devices. S3 has end-to-end integrity checking on every object upload and verifies that all data is correctly and redundantly stored across multiple storage devices before it considers your upload to be successful. Once your data is stored in S3, S3 continuously monitors data durability over time with periodic integrity checks of all data at rest. S3 also actively monitors the redundancy of your data to help verify that your objects are able to tolerate the concurrent failure of multiple storage devices.\n",
      "Pattern: What is an AWS Lambda function? \n",
      "Response: The code you run on AWS Lambda is uploaded as a Lambda function. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a stateless style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones. \n",
      "Pattern: How can I manage my AWS Lambda functions? \n",
      "Response: How can I manage my AWS Lambda functions? \n",
      "Pattern: What AWS service supports data archiving for long-term storage? \n",
      "Response: Use Amazon S3 Glacier for data archiving. It provides low-cost storage with retrieval times ranging from minutes to hours.\n",
      "Pattern: Can I submit a multi-region Spot Fleet request? \n",
      "Response: No, we do not support multi-region Fleet requests.\n",
      "Pattern: How does EFA communication work? \n",
      "Response: EFA devices provide all ENA devices' functionalities plus a new OS bypass hardware interface that allows user-space applications to communicate directly with the hardware-provided reliable transport functionality. Most applications will use existing middleware, such as the MPI, to interface with EFA. AWS has worked with a number of middleware providers to ensure support for the OS bypass functionality of EFA. Please note that communication using the OS bypass functionality is limited to instances within a single subnet of a virtual private cloud (VPC).\n",
      "Pattern: Why should I use AWS Fargate? \n",
      "Response: AWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers. AWS Fargate is compatible with both Amazon ECS and Amazon EKS. AWS Fargate makes it easy to scale and manage cloud applications by shifting as much management of the underlying infrastructure resources to AWS so development teams can focus on writing code that solve business problems. Shifting tasks such as server management, resource allocation, and scaling to AWS does not only improve your operational posture, but also accelerates the process of going from idea to production on the cloud and lowers the total cost of ownership (TCO). With multiple CPU architectures and operating systems supported, you can enjoy the serverless benefits of cost, agility and scale across a wide variety of applications. \n",
      "Pattern: How does Amazon EKS work? \n",
      "Response: Amazon EKS works by provisioning (starting) and managing the Kubernetes control plane and worker nodes for you. At a high level, Kubernetes consists of two major components: a cluster of 'worker nodes' running your containers, and the control plane managing when and where containers are started on your cluster while monitoring their status.\n",
      "Pattern: For what time period will the AWS Free Tier for Amazon RDS be available to me? \n",
      "Response: New AWS accounts receive 12 months of AWS Free Tier access. Please see the AWS Free Tier FAQs for more information. \n",
      "Pattern: Network Data Transferred Out: \n",
      "Response: Amazon S3 Data Transfer Out pricing is summarized on the Amazon S3 pricing page. For Amazon S3, this charge applies whenever data is read from any of your buckets from a location outside of the given Amazon S3 Region.\n",
      "Pattern: How can I communicate the AZ of an On-Demand Capacity Reservation with another account, given AZ name mappings could be different across AWS accounts? \n",
      "Response: You can now use an Availability Zone ID (AZ ID) instead of an AZ name. An AZ ID is a static reference and provides a consistent way of identifying the location of a resource across all your accounts. This makes it easier for you to provision resources centrally in a single account and share them across multiple accounts.\n",
      "Pattern: What use cases does Amazon RDS Proxy address? \n",
      "Response: Amazon RDS Proxy addresses a number of use cases related to scalability, availability, and security of your applications, including: Applications with unpredictable workloads: Applications that support highly variable workloads may attempt to open a burst of new database connections. Amazon RDS Proxy's connection governance allows you to gracefully scale applications dealing with unpredictable workloads by efficiently reusing database connections. First, RDS Proxy enables multiple application connections to share a database connection for efficient use of database resources. Second, RDS Proxy allows you to maintain predictable database performance by regulating the number of database connections that are opened. Third, RDS Proxy removes requests that cannot be served to preserve the overall performance and availability of the application. Applications that frequently open and close database connections: Applications built on technologies such as Serverless, PHP, or Ruby on Rails may open and close database connections frequently to serve application requests. Amazon RDS Proxy maintains a pool of database connections to avoid unnecessary stress on database compute and memory for establishing new connections. Applications that keep connections open but idle: Applications in industries such as SaaS or eCommerce may keep database connections idling to minimize the response time when a customer reengages. Instead of overprovisioning databases to support mostly idling connections, you can use Amazon RDS Proxy to hold idling connections while only establishing database connections as required to optimally serve active requests. Applications requiring availability through transient failures: With Amazon RDS Proxy, you can build applications that can transparently tolerate database failures without needing to write complex failure handling code. RDS Proxy automatically routes traffic to a new database instance while preserving application connections. RDS Proxy also bypasses Domain Name System (DNS) caches to reduce failover times by up to 66% for Amazon RDS and Aurora Multi-AZ databases. During database failovers, the application may experience increased latencies and ongoing transactions may have to be retried. Improved security and centralized credentials management: Amazon RDS Proxy aids you in building more secure applications by giving you a choice to enforce IAM based authentication with relational databases. RDS Proxy also enables you to centrally manage database credentials through AWS Secrets Manager. \n",
      "Pattern: How can I grant temporary access to my S3 bucket for a specific user without sharing AWS credentials? \n",
      "Response: Generate pre-signed URLs using AWS SDKs or the AWS Management Console to grant temporary access to your S3 bucket without sharing credentials.\n",
      "Pattern: What's the recommended way to handle long-term data retention for my Amazon RDS database backups? \n",
      "Response: Store your Amazon RDS backups in Amazon S3 for long-term data retention, ensuring durability and easy retrieval.\n",
      "Pattern: How will I be charged for using AWS Lambda functions? \n",
      "Response: AWS Lambda is priced on a pay-per-use basis. Please see the AWS Lambda pricing page for details. \n",
      "Pattern: I have a variable workload with unpredictable traffic. How can I optimize costs for my database? \n",
      "Response: Consider using Amazon RDS On-Demand Instances for flexibility or Amazon RDS Aurora Serverless for automatic cost optimization based on actual usage.\n",
      "Pattern: How will I be charged if my Spot instance is stopped or interrupted? \n",
      "Response: If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, you will not be charged for that usage. However, if you stop or terminate the Spot instance yourself, you will be charged to the nearest second. If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows or Red Hat Enterprise Linux (RHEL) and you stop or terminate the Spot instance yourself, you will be charged for an entire hour.\n",
      "Pattern: How do I coordinate calls between multiple Lambda functions? \n",
      "Response: You can use Amazon Step Functions to coordinate multiple invoking Lambda functions. You can invoke multiple Lambda functions serially, passing the output of one to the other, or in parallel. See our documentation for more details. \n",
      "Pattern: Can I customize my access levels? \n",
      "Response: No. You can only use the three pre-defined access levels (READ/WRITE/READWRITE) that S3 Access Grants offers.\n",
      "Pattern: How do I access resources in Amazon VPC from my AWS Lambda function? \n",
      "Response: You can enable Lambda functions to access resources in your VPC by specifying the subnet and security group as part of your function configuration. Lambda functions configured to access resources in a particular VPC will not have access to the internet as a default configuration. To grant internet to these functions, use internet gateways. By default, Lambda functions communicate with resources in a dual-stack VPC over IPv4. You can configure your functions to access resources in a dual-stack VPC over IPv6. For more details on Lambda functions configured with VPC, see Lambda Private Networking with VPC. \n",
      "Pattern: What are the specifications of the first-generation AWS Graviton Processors? \n",
      "Response: AWS Graviton processors are custom designed by AWS utilizing Amazon's extensive expertise in building platform solutions for cloud applications running at scale. These processors are based on the 64-bit Arm instruction set and feature Arm Neoverse cores as well as custom silicon designed by AWS. The cores operate at a frequency of 2.3 GHz.\n",
      "Pattern: How can I store and retrieve large amounts of data in the cloud? \n",
      "Response: Use Amazon S3, a scalable object storage service designed for storing and retrieving any amount of data.\n",
      "Pattern: Will I be able to access my EBS snapshots using the regular Amazon S3 APIs? \n",
      "Response: No, EBS snapshots are only available through the Amazon EC2 APIs.\n",
      "Pattern: Is AWS Lambda ephemeral storage encrypted? \n",
      "Response: Yes. All data stored in ephemeral storage is encrypted at rest with a key managed by AWS. \n",
      "Pattern: How do I make an AWS Lambda function respond to changes in an Amazon S3 bucket? \n",
      "Response: From the AWS Lambda console, you can select a function and associate it with notifications from an Amazon S3 bucket. Alternatively, you can use the Amazon S3 console and configure the bucket's notifications to send to your AWS Lambda function. This same functionality is also available through the AWS SDK and CLI. \n",
      "Pattern: What happens to my Spot instance when it gets interrupted? \n",
      "Response: You can choose to have your Spot instances terminated, stopped or hibernated upon interruption. Stop and hibernate options are available for persistent Spot requests and Spot Fleets with the maintain option enabled. By default, your instances are terminated.\n",
      "Pattern: How do I access my file system from outside my VPC? \n",
      "Response: Amazon EC2 instances within your VPC can access your file system directly. On-premises servers can mount your file systems via an AWS Direct Connect connection to your VPC.\n",
      "Pattern: How can I manage my AWS Lambda functions? \n",
      "Response: How can I manage my AWS Lambda functions? \n",
      "Pattern: What types of identity are supported for S3 Access Grants permission grants? \n",
      "Response: S3 Access Grants supports two kinds of identities: enterprise user or group identities from AWS Identity Center, and AWS IAM principals including IAM users and roles. When you use S3 Access Grants with AWS Identity Center, you can define data permissions on the basis of directory group memberships. AWS Identity Center is an AWS service that connects to commonly-used identity providers, including Entra ID, Okta, Ping, and others. In addition to supporting directory identities via AWS Identity Center, S3 Access Grants also supports permission rules for AWS IAM principal including IAM users and roles. This is for use cases where you either manage a custom identity federation not through AWS Identity Center but via IAM and SAML assertion (example implementation), or manage application identities based on IAM principals, and still would like to use S3 Access Grants due to its scalability and auditability.\n",
      "Pattern: What are AWS Lambda functions powered by Graviton2 processors? \n",
      "Response: AWS Lambda allows you to run your functions on either x86-based or Arm-based processors. AWS Graviton2 processors are custom built by Amazon Web Services using 64-bit Arm Neoverse cores to deliver increased price performance for your cloud workloads. Customers get the same advantages of AWS Lambda, running code without provisioning or managing servers, automatic scaling, high availability, and only paying for the resources you consume. \n",
      "Pattern: I need to host a static website with HTTPS support. What AWS service should I use in conjunction with S3? \n",
      "Response: Combine Amazon S3 for static content storage with Amazon CloudFront for global content delivery and HTTPS support.\n",
      "Pattern: What is a serverless application? \n",
      "Response: Lambda-based applications (also referred to as serverless applications) are composed of functions triggered by events. A typical serverless application consists of one or more functions triggered by events such as object uploads to Amazon S3, Amazon SNS notifications, or API actions. These functions can stand alone or leverage other resources such as DynamoDB tables or Amazon S3 buckets. The most basic serverless application is simply a function. \n",
      "Pattern: Do I need to enable backups for my DB Instance or is it done automatically? \n",
      "Response: By default, Amazon RDS enables automated backups of your DB instance with a 7-day retention period. If you would like to modify your backup retention period, you can do so using the RDS Console, the CreateDBInstance API (when creating a new DB Instance), or the ModifyDBInstance API (for existing instances). You can use these methods to change the RetentionPeriod parameter to any number from 0 (which will disable automated backups) to the desired number of days, up to 35. The value cannot be set to 0 if the DB instance is a source to Read Replicas. For more information on automated backups, please refer to the Amazon RDS User Guide. \n",
      "Pattern: What is Container Image Support for AWS Lambda? \n",
      "Response: AWS Lambda now enables you to package and deploy functions as container images. Customers can leverage the flexibility and familiarity of container tooling, and the agility and operational simplicity of AWS Lambda to build applications. \n",
      "Pattern: How does instance size flexibility work? \n",
      "Response: EC2 uses the scale shown below to compare different sizes within an instance family. In the case of instance size flexibility on RIs, this scale is used to apply the discounted rate of RIs to the normalized usage of the instance family. For example, if you have an m5.2xlarge RI that is scoped to a region, then your discounted rate could apply towards the usage of 1 m5.2xlarge or 2 m5.xlarge instances.\n",
      "Pattern: What is S3 Intelligent-Tiering? \n",
      "Response: S3 Intelligent-Tiering is the first cloud storage that automatically reduces your storage costs on a granular object level by automatically moving data to the most cost-effective access tier based on access frequency, without performance impact, retrieval fees, or operational overhead. S3 Intelligent-Tiering delivers milliseconds latency and high throughput performance for frequently, infrequently, and rarely accessed data in the Frequent, Infrequent, and Archive Instant Access tiers. For a small monthly object monitoring and automation charge, S3 Intelligent-Tiering monitors the access pattern and moves the objects automatically from one tier to another. There are no retrieval charges in S3 Intelligent-Tiering, so you won't see unexpected increases in storage bills when access pattern change.\n",
      "Pattern: What happens when an Amazon RDS DB engine version is deprecated? \n",
      "Response: When a minor version of a database engine is deprecated in Amazon RDS, we will provide a three (3) month period after the announcement before beginning automatic upgrades. At the end of this period, all instances still running the deprecated minor version will be scheduled for automatic upgrade to the latest supported minor version during their scheduled maintenance windows. When a major version of the database engine is deprecated in Amazon RDS, we will provide a minimum six (6) month period after the announcement of a deprecation for you to initiate an upgrade to a supported major version. At the end of this period, an automatic upgrade to the next major version will be applied to any instances still running the deprecated version during their scheduled maintenance windows. \n",
      "Pattern: What can I do with Amazon EC2? \n",
      "Response: Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables compute in the cloud. The Amazon EC2 simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use.\n",
      "Pattern: I need to run a PostgreSQL database with improved performance and scalability. What AWS service should I choose? \n",
      "Response: Amazon RDS for PostgreSQL provides improved performance and scalability for PostgreSQL databases with features like Amazon Aurora.\n",
      "Pattern: Why should I use an access point? \n",
      "Response: S3 Access Points simplify how you manage data access to your shared datasets on S3. You no longer have to manage a single, complex bucket policy with hundreds of different permission rules that need to be written, read, tracked, and audited. With S3 Access Points, you can create access points or delegate permissions to trusted accounts to create cross-account access points on your bucket. This permits access to shared data sets with policies tailored to the specific application.\n",
      "Pattern: How will I be charged and billed for my use of Amazon RDS? \n",
      "Response: You pay only for what you use and there are no minimum or setup fees. You are billed based on: DB instance hours - Based on the class (e.g. db.t2.micro, db.m4.large) of the DB instance consumed. Partial DB instance hours consumed are billed in one-second increments with a 10 minute minimum charge following a billable status change, such as creating, starting, or modifying the DB instance class. For additional details, read our what's new announcement. Storage (per GB per month) - Storage capacity you have provisioned to your DB instance. If you scale your provisioned storage capacity within the month, your bill will be pro-rated. I/O requests per month - Total number of storage I/O requests you have (for Amazon RDS Magnetic Storage and Amazon Aurora only) Provisioned IOPS per month - Provisioned IOPS rate, regardless of IOPS consumed (for Amazon RDS Provisioned IOPS (SSD) Storage only) Backup Storage - Backup storage is the storage associated with your automated database backups and any customer-initiated database snapshots. Increasing your backup retention period or taking additional database snapshots increases the backup storage consumed by your database. Data transfer - Internet data transfer in and out of your DB instance. For Amazon RDS pricing information, please visit the pricing section on the Amazon RDS product page. \n",
      "Pattern: What can I do with Amazon S3 Event Notifications? \n",
      "Response: Amazon S3 Event Notifications let you run workflows, send alerts, or perform other actions in response to changes in your objects stored in S3. You can use S3 Event Notifications to set up triggers to perform actions including transcoding media files when they are uploaded, processing data files when they become available, and synchronizing S3 objects with other data stores. You can also set up event notifications based on object name prefixes and suffixes. For example, you can choose to receive notifications on object names that start with images/.\"\n",
      "Pattern: Which instances and operating systems support hibernation? \n",
      "Response: Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.\n",
      "Pattern: When should I use memory-optimized instances? \n",
      "Response: Memory-optimized instances offer large memory size for memory intensive applications including in-memory applications, in-memory databases, in-memory analytics solutions, HPC, scientific computing, and other memory-intensive applications.\n",
      "Pattern: How can I manage my AWS Lambda functions? \n",
      "Response: How can I manage my AWS Lambda functions? \n",
      "Pattern: What does it mean to run a DB Instance as a read replica? \n",
      "Response: Read replicas make it easier to take advantage of supported engines' built-in replication functionality to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create a read replica with a few clicks in the AWS Management Console or using the CreateDBInstanceReadReplica API. Once the read replica is created, database updates on the source DB instance will be replicated using a supported engine's native, asynchronous replication. You can create multiple read replicas for a given source DB Instance and distribute your application's read traffic amongst them. Since read replicas use supported engines' built-in replication, they are subject to its strengths and limitations. In particular, updates are applied to your read replica(s) after they occur on the source DB instance, and replication lag can vary significantly. Read replicas can be associated with Multi-AZ deployments to gain read scaling benefits in addition to the enhanced database write availability and data durability provided by Multi-AZ deployments. \n",
      "Pattern: What versions does Amazon RDS Blue/Green Deployments support? \n",
      "Response: Amazon RDS Blue/Green Deployments are available in for Amazon Aurora MySQL-Compatible Edition versions 5.6 and higher, RDS for MySQL versions 5.7 and higher, and RDS for versions MariaDB versions 10.2 and higher. Blue/Green Deployments are also supported for Amazon Aurora PostgreSQL-Compatible Edition and Amazon RDS for PostgreSQL for versions 11.21 and higher, 12.16 and higher, 13.12 and higher, 14.9 and higher, and 15.4 and higher. Learn more about available versions in the Amazon Aurora and Amazon RDS documentation. \n",
      "Pattern: Will my standby be in the same Region as my primary? \n",
      "Response: Yes. Your standby is automatically provisioned in a different Availability Zone of the same Region as your DB instance primary. \n",
      "Pattern: How is S3 Access Grants priced? \n",
      "Response: S3 Access Grants is charged based on the number of requests to S3 Access Grants. See the pricing page for details.\n",
      "Pattern: What is S3 Transfer Acceleration? \n",
      "Response: Amazon S3 Transfer Acceleration creates fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. S3 Transfer Acceleration leverages Amazon CloudFront's globally distributed AWS Edge locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.\n",
      "Pattern: What can I do with Amazon S3 that I cannot do with an on-premises solution? \n",
      "Response: Amazon S3 lets you leverage Amazon's own benefits of massive scale with no up-front investment or performance compromises. By using Amazon S3, it is inexpensive and simple to ensure your data is quickly accessible, always available, and secure.\n",
      "Pattern: Which pricing dimensions can I set for the RIs that I want to list? \n",
      "Response: Using the RI Marketplace, you can set an upfront price you'd be willing to accept. You cannot set the hourly price (which will remain the same as was set on the original RI), and you will not receive any funds collected from payments associated with the hourly prices.\n",
      "Pattern: How will I know when I can start selling on the RI Marketplace? \n",
      "Response: You can start selling on the RI Marketplace after you have added a bank account through the registration pipeline. Once activation is complete, you will receive a confirmation email. However, it is important to note that you will not be able to receive disbursements until we are able to receive verification from your bank, which may take up to two weeks, depending on the bank you use.\n",
      "Pattern: Can I tag an Amazon EC2 Fleet? \n",
      "Response: Yes. You can tag an EC2 Fleet request to create business-relevant tag groupings to organize resources along technical, business, and security dimensions.\n",
      "Pattern: Can I submit a multi-region Amazon EC2 Fleet request? \n",
      "Response: No, we do not support multi-region EC2 Fleet requests.\n",
      "Pattern: What is the difference between hibernate and stop? \n",
      "Response: In the case of hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shut down and RAM is cleared.\n",
      "Pattern: What is Enhanced Monitoring for Amazon RDS? \n",
      "Response: Enhanced Monitoring for Amazon RDS gives you deeper visibility into the health of your Amazon RDS instances. Just turn on the  Enhanced Monitoring  option for your Amazon RDS DB Instance and set a granularity and Enhanced Monitoring will collect vital operating system metrics and process information, at the defined granularity. For an even deeper level of diagnostics and visualization of your database load, and a longer data retention period, you can try Performance Insights. \n",
      "Pattern: What are Amazon S3 Access Grants? \n",
      "Response: Amazon S3 Access Grants map identities in directories such as Active Directory, or AWS Identity and Access Management (IAM) principals, to datasets in S3. This helps you manage data permissions at scale by automatically granting S3 access to end-users based on their corporate identity. Additionally, S3 Access Grants log end-user identity and the application used to access S3 data in AWS CloudTrail. This helps to provide a detailed audit history down to the end-user identity for all access to the data in your S3 buckets.\n",
      "Pattern: What is an AWS Lambda function? \n",
      "Response: The code you run on AWS Lambda is uploaded as a Lambda function. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a stateless style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones. \n",
      "Pattern: What is the consistency model for Amazon S3? \n",
      "Response: Amazon S3 delivers strong read-after-write consistency automatically, without changes to performance or availability, without sacrificing regional isolation for applications, and at no additional cost.\n",
      "Pattern: What encryption algorithm is used to encrypt Amazon EC2 NVMe instance storage? \n",
      "Response: Amazon EC2 NVMe instance storage is encrypted using an XTS-AES-256 block cipher.\n",
      "Pattern: What is the Lambda Runtime Interface Emulator (RIE)? \n",
      "Response: The Lambda Runtime Interface Emulator is a proxy for the Lambda Runtime API,which allows customers to locally test their Lambda function packaged as a container image. It is a lightweight web server that converts HTTP requests to JSON events and emulates the Lambda Runtime API. It allows you to locally test your functions using familiar tools such as cURL and the Docker CLI (when testing functions packaged as container images). It also simplifies running your application on additional compute services. You can include the Lambda Runtime Interface Emulator in your container image to have it accept HTTP requests natively instead of the JSON events required for deployment to Lambda. This component does not emulate the Lambda orchestrator, or security and authentication configurations. The Runtime Interface Emulator is open sourced on GitHub. You can get started by downloading and installing it on your local machine. \n",
      "Pattern: Why would I use Amazon RDS Proxy? \n",
      "Response: Amazon RDS Proxy is a fully managed, highly available, and easy-to-use database proxy feature of Amazon RDS that enables your applications to: 1) improve scalability by pooling and sharing database connections, 2) improve availability by reducing database failover times by up to 66% and preserving application connections during failovers, and 3) improve security by optionally enforcing AWS IAM authentication to databases and securely storing credentials in AWS Secrets Manager. \n",
      "Pattern: How can I manage my AWS Lambda functions? \n",
      "Response: How can I manage my AWS Lambda functions? \n",
      "Pattern: What's the advantage of using Dedicated Hosts over other EC2 options? \n",
      "Response: Dedicated Hosts offer the advantage of maximum visibility and control over the underlying physical servers. They provide predictability and isolation for your instances.\n",
      "Pattern: I have a growing dataset. What's the best way to handle read scalability for my database? \n",
      "Response: Consider using Amazon Aurora. It is a MySQL and PostgreSQL-compatible relational database engine designed for performance and scalability.\n",
      "Pattern: When should I use Amazon S3, Amazon EFS, or AWS Lambda ephemeral storage for my serverless applications? \n",
      "Response: If your application needs durable, persistent storage, consider using Amazon S3 or Amazon EFS. If your application requires storing data needed by code in a single function invocation, consider using AWS Lambda ephemeral storage as a transient cache. To learn more, please see Choosing between AWS Lambda data storage options in web apps. \n",
      "Pattern: Which volume type should I choose? \n",
      "Response: Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1 and io2) and General Purpose SSD (gp2 and gp3). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O pattern. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information, see the Amazon EBS overview.\n",
      "Pattern: What is Versioning? \n",
      "Response: Versioning allows you to preserve, retrieve, and restore every version of every object stored in an Amazon S3 bucket. Once you enable Versioning for a bucket, Amazon S3 preserves existing objects anytime you perform a PUT, POST, COPY, or DELETE operation on them. By default, GET requests will retrieve the most recently written version. Older versions of an overwritten or deleted object can be retrieved by specifying a version in the request.\n",
      "Pattern: What can I do with Amazon EC2? \n",
      "Response: Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables compute in the cloud. The Amazon EC2 simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use.\n"
     ]
    }
   ],
   "source": [
    "arr_of_actual_responses = rdf['response'].tolist()\n",
    "arr_of_predicted_responses = []\n",
    "\n",
    "for index, row in rdf.iterrows():\n",
    "    result = search(row[\"pattern\"])\n",
    "    print(f\"Pattern: {result[1]['_source']['pattern']} \")\n",
    "    print(f\"Response: {result[1]['_source']['response']}\")\n",
    "    arr_of_predicted_responses.append(result[1]['_source']['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes, to replicate objects from S3 Object Lock enabled buckets you need to grant two new permissions, s3:GetObjectRetention and s3:GetObjectLegalHold, on the source bucket in the IAM role that you use to set up replication. Alternatively, if the IAM role has an s3:Get* permission, it satisfies the requirement. For more information see the documentation on using S3 Object Lock with S3 Replication.', 'Hpc7a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.6 or later, SUSE Linux Enterprise Server 12 SP3 or later, CentOS 7 or later, and FreeBSD 11.1 or later.', 'Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2 while abstracting the details of the underlying storage media in use. Amazon EC2 instance instances with local HDD or NVMe storage provide directly attached, high performance storage building blocks that can be used for a variety of storage applications. Dense-storage instances are specifically targeted at customers who want high sequential read/write access to large data sets on local storage, e.g. for Hadoop distributed computing and massively parallel processing data warehousing.', 'For variable demand workloads, a combination of On-Demand and Spot Instances can be cost-effective. Use On-Demand for baseline capacity and Spot Instances to handle spikes in demand.', 'To get started, you can purchase an RI from the EC2 console or by using the AWS CLI. Simply specify the instance type, platform, tenancy, term, payment option, and region or AZ.', 'No. Instance spots in an On-Demand Capacity Reservation are available on a first-come, first-served basis to any account that has shared access.', 'An ENA ENI provides traditional IP networking features necessary to support VPC networking. An EFA ENI provides all the functionality of an ENA ENI, plus hardware support for applications to communicate directly with the EFA ENI without involving the instance kernel (OS-bypass communication) using an extended programming interface. Due to the advanced capabilities of the EFA ENI, EFA ENIs can only be attached at launch or to stopped instances.', 'The Convertible RI is useful for customers who can commit to using EC2 instances for a three-year term in exchange for a significant discount on their EC2 usage, are uncertain about their instance needs in the future, or want to benefit from changes in price.', 'Use Amazon Athena for querying and analyzing data directly from Amazon S3 without the need for data loading.', 'Yes. Convertible RIs offer you the option to change the instance type, operating system, tenancy or payment option of your RI during its term. Please refer to the Convertible RI section of the FAQ for additional information.', 'AWS offers two types of Savings Plans:', 'Opt for Dedicated Hosts if your application has licensing restrictions that require you to run on dedicated physical servers.', 'IAM policies define permissions for the entities you attach them to. For example, to grant access to an IAM role, attach a policy to the role. The permissions defined in the policy determine whether requests are allowed or denied. You also can attach policies to some resources, such as Amazon S3 buckets, to grant direct, cross-account access. And you can attach policies to an AWS organization or organizational unit to restrict access across multiple accounts. AWS evaluates these policies when an IAM role makes a request. For more information, see Identity-based policies.', 'AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). AWS Fargate makes it easy to focus on building your applications by eliminating the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design. ', 'Use Amazon RDS with Amazon Redshift for seamless integration with data analytics services, enabling efficient data processing and analysis.', 'AWS Lambda functions powered by AWS Graviton2 processors are 20% cheaper compared to x86-based Lambda functions. The Lambda free tier applies to AWS Lambda functions powered by x86 and Arm-based architectures. ', 'We recommend that you launch the minimum number of instances required to participate in a cluster in a single launch. For very large clusters, you should launch multiple placement groups, e.g. two placement groups of 128 instances, and combine them to create a larger, 256 instance cluster.', 'Amazon S3 is suitable for storing and serving user uploads in a scalable and cost-effective manner for your mobile application.', 'Yes, all data is encrypted in an AWS Nitro hardware module prior to being written on the locally attached SSDs offered via NVMe instance storage.', 'Please refer to the AWS Global Infrastructure Region Table. ', 'Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance or burstable performance; Compute Optimized instances have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerated Computing instances use hardware accelerators, or co-processors, to perform functions such as floating point number calculations, graphics processing, or data pattern matching, more efficiently than is possible in software running on CPUs; Storage Optimized Instances provide low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, as well as dense HDD-storage instances, which provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size.', 'Utilize Amazon RDS Cross-Region Read Replicas to enhance availability by replicating your database to a different AWS region.', 'Lambda SnapStart is a simple function level configuration that can be configured for new and existing Java functions by using Lambda API, the AWS Management Console, AWS Command Line Interface (CLI), AWS SDK, AWS Cloud Development Kit (CDK), AWS CloudFormation, and the AWS Serverless Application Model (SAM). When you configure Lambda SnapStart, every function version that is published thereafter benefits from the improved startup performance offered by Lambda SnapStart. To learn more about Lambda SnapStart, see the documentation. ', \"Amazon RDS Proxy addresses a number of use cases related to scalability, availability, and security of your applications, including: Applications with unpredictable workloads: Applications that support highly variable workloads may attempt to open a burst of new database connections. Amazon RDS Proxy's connection governance allows you to gracefully scale applications dealing with unpredictable workloads by efficiently reusing database connections. First, RDS Proxy enables multiple application connections to share a database connection for efficient use of database resources. Second, RDS Proxy allows you to maintain predictable database performance by regulating the number of database connections that are opened. Third, RDS Proxy removes requests that cannot be served to preserve the overall performance and availability of the application. Applications that frequently open and close database connections: Applications built on technologies such as Serverless, PHP, or Ruby on Rails may open and close database connections frequently to serve application requests. Amazon RDS Proxy maintains a pool of database connections to avoid unnecessary stress on database compute and memory for establishing new connections. Applications that keep connections open but idle: Applications in industries such as SaaS or eCommerce may keep database connections idling to minimize the response time when a customer reengages. Instead of overprovisioning databases to support mostly idling connections, you can use Amazon RDS Proxy to hold idling connections while only establishing database connections as required to optimally serve active requests. Applications requiring availability through transient failures: With Amazon RDS Proxy, you can build applications that can transparently tolerate database failures without needing to write complex failure handling code. RDS Proxy automatically routes traffic to a new database instance while preserving application connections. RDS Proxy also bypasses Domain Name System (DNS) caches to reduce failover times by up to 66% for Amazon RDS and Aurora Multi-AZ databases. During database failovers, the application may experience increased latencies and ongoing transactions may have to be retried. Improved security and centralized credentials management: Amazon RDS Proxy aids you in building more secure applications by giving you a choice to enforce IAM based authentication with relational databases. RDS Proxy also enables you to centrally manage database credentials through AWS Secrets Manager. \", 'Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.', 'VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.', 'Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don\\'t charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.', 'A Spot Fleet allows you to automatically request and manage multiple Spot instances that provide the lowest price per unit of capacity for your cluster or application, like a batch processing job, a Hadoop workflow, or an HPC grid computing job. You can include the instance types that your application can use. You define a target capacity based on your application needs (in units including instances, vCPUs, memory, storage, or network throughput) and update the target capacity after the fleet is launched. Spot fleets enable you to launch and maintain the target capacity, and to automatically request resources to replace any that are disrupted or manually terminated. Learn more about Spot fleets.', 'Yes. Enable automatic backups on your source DB Instance before adding read replicas by setting the backup retention period to a value other than 0. Backups must remain enabled for read replicas to work. ', 'There will be no change to billing and pricing. We will continue to support the same pricing models we support today for the previous generation instances (On-Demand, 1yr/3yr Reserved Instance, Savings Plan, Spot).', 'No. Each Lambda function will be able to access one EFS file system. ', 'No, you will not receive a prorated refund for the upfront portion of the AWS Premium Support Fee.', 'No. Spot fleet requests allow you to place multiple Spot Instance requests simultaneously, and are subject to the same availability and prices as a single Spot Instance request. For example, if no resources are available for the instance types listed in your Spot Fleet request, we may be unable to fulfill your request partially or in full. We recommend that you to include all the possible instance types and availability zones that are suitable for your workloads in the Spot Fleet.', 'Amazon RDS is the recommended service for running a fully-managed database with minimal administrative effort.', 'If you want to take advantage of the capacity reservation, then you should buy an RI in a specific AZ.', 'For high availability, use Amazon RDS Multi-AZ deployments. It automatically replicates your database to a standby instance in a different Availability Zone.', 'Failover is automatically handled by Amazon RDS so that you can resume database operations as quickly as possible without administrative intervention. When failing over, Amazon RDS simply flips the canonical name record (CNAME) for your DB instance to point at the standby, which is in turn promoted to become the new primary. We encourage you to follow best practices and implement database connection retry at the application layer. Failovers, as defined by the interval between the detection of the failure on the primary and the resumption of transactions on the standby, typically complete within one to two minutes. Failover time can also be affected by whether large uncommitted transactions must be recovered; the use of adequately large instance types is recommended with Multi-AZ for best results. AWS also recommends the use of Provisioned IOPS with Multi-AZ instances, for fast, predictable, and consistent throughput performance. ', 'Data ingestion and archival charges for vended logs apply when you publish flow logs to CloudWatch Logs or to Amazon S3. For more information and examples, see Amazon CloudWatch Pricing. You can also track charges from publishing flow logs using cost allocation tags. ', 'Functionally, reserved instances and on-demand DB instances are exactly the same. The only difference is how your DB instance(s) are billed. With Reserved Instances, you purchase a one- or three-year reservation and in return receive a lower effective hourly usage rate (compared with on-demand DB instances) for the duration of the term. Unless you purchase reserved instances in a Region, all DB instances will be billed at on-demand hourly rates. ', 'Yes. Mount targets for Amazon EFS are associated with a subnet in a VPC. The AWS Lambda function needs to be configured to access that VPC. ', 'Visit the Region Table page to see product service availability by Region.', 'High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for low latency networking.', 'No. Lambda SnapStart and PC cannot be enabled at the same time, on the same function. ', 'Yes. You can use NPM packages as well as custom packages. Learn more here. ', 'Amazon RDS is the recommended service for running a fully-managed database with minimal administrative effort.', 'No, you cannot enable hibernation on an existing instance (running or stopped). This needs to be enabled during instance launch.', 'Instances running on the Nitro Hypervisor support a maximum of 27 additional PCI devices for EBS volumes and VPC ENIs. Each EBS volume or VPC ENI uses a PCI device. For example, if you attach 3 additional network interfaces to an instance that uses the Nitro Hypervisor, you can attach up to 24 EBS volumes to that instance.', 'You can resume by calling the StartInstances API as you would for a regular stopped instance. You can also do this through the console by selecting your instance, then clicking Actions > Instance State > Start.', 'No, the vCPU-based limits only apply to running On-Demand instances and Spot Instances.', 'On failure, Lambda functions being invoked synchronously will respond with an exception. Lambda functions being invoked asynchronously are retried at least 3 times. Events from Amazon Kinesis streams and Amazon DynamoDB streams are retried until the Lambda function succeeds or the data expires. Kinesis and DynamoDB Streams retain data for a minimum of 24 hours. ', 'You can now use an Availability Zone ID (AZ ID) instead of an AZ name. An AZ ID is a static reference and provides a consistent way of identifying the location of a resource across all your accounts. This makes it easier for you to provision resources centrally in a single account and share them across multiple accounts.', 'S3 Transfer Acceleration is designed to optimize transfer speeds from across the world into S3 buckets. If you are uploading to a centralized bucket from geographically dispersed locations or if you regularly transfer GBs or TBs of data across continents, you may save hours or days of data transfer time with S3 Transfer Acceleration.', \"AWS Lambda automatically monitors Lambda functions on your behalf, reporting real-time metrics through Amazon CloudWatch, including total requests, account-level and function-level concurrency usage, latency, error rates, and throttled requests. You can view statistics for each of your Lambda functions via the Amazon CloudWatch console or through the AWS Lambda console. You can also call third-party monitoring APIs in your Lambda function.  Visit Troubleshooting CloudWatch metrics to learn more. Standard charges for AWS Lambda apply to use Lambda's built-in metrics. \", \"Over time, Amazon RDS adds support for new major and minor database engine versions. The number of new versions supported will vary based on the frequency and content of releases and patches from the engine's vendor or development organization and the outcome of a thorough vetting of these releases and patches by our database engineering team. However, as a general guidance, we aim to support new engine versions within 5 months of their general availability. \", 'X2gd is ideal for customers with Arm-compatible memory bound scale-out workloads such as Redis and Memcached in-memory databases, that need low latency memory access and benefit from more memory per vCPU. X2gd is also well suited for relational databases such as PostgreSQL, MariaDB, MySQL, and RDS Aurora. Customers who run memory intensive workloads such as Apache Hadoop, real-time analytics, and real-time caching servers will benefit from 1:16 vCPU to memory ratio of X2gd. Single threaded workloads such as EDA backend verification jobs will benefit from physical core and more memory of X2gd instances, allowing them to consolidate more workloads on to a single instance. X2gd instance also feature local NVMe SSD block storage to improve response times by acting as a caching layer.', 'The AWS Free Tier for Amazon RDS offer provides free use of Single-AZ Micro DB instances running MySQL, MariaDB, PostgreSQL, and SQL Server Express Edition. The free usage tier is capped at 750 instance hours per month. Customers also receive 20 GB of General Purpose (SSD) database storage and 20 GB of backup storage for free per month. ', 'Yes. Amazon EC2 Auto Scaling is a fully managed service designed to launch or terminate Amazon EC2 instances automatically to help ensure you have the correct number of Amazon EC2 instances available to handle the load for your application. EC2 Auto Scaling helps you maintain application availability through fleet management for EC2 instances, which detects and replaces unhealthy instances, and by scaling your Amazon EC2 capacity up or down automatically according to conditions you define. You can use EC2 Auto Scaling to automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs.', 'If you have a valid use case for sending emails to port 25 (SMTP) from EC2, please submit a Request to Remove Email Sending Limitations to have these restrictions lifted. You can alternately send emails using a different port, or leverage an existing authenticated email relay service such as Amazon Simple Email Service (Amazon SES).', 'ENA Express is supported on Graviton-, Intel-, and AMD-based EC2 instances. It is supported on compute-optimized, memory-optimized, general purpose and storage-optimized based instances. For a complete list of supported instances, please see the ENA Express user guide.', 'Yes. Since Multi-AZ DB instances address a different need than read replicas, it makes sense to use the two in conjunction for production deployments and to associate a read replica with a Multi-AZ DB Instance deployment. The  source  Multi AZ-DB instance provides you with enhanced write availability and data durability, and the associated read replica would improve read traffic scalability. ', 'Yes, you can enable Multi-Attach on an EBS Provisioned IOPS io1 volume to allow a volume to be concurrently attached to up to sixteen Nitro-based EC2 instances within the same Availability Zone. For more information on Amazon EBS Multi-Attach, see the EBS product page.', \"Unlike conversions between Convertible RIs with an upfront value, since you're converting between RIs without an upfront cost, there will not be a true-up charge. However, the amount you pay on an hourly basis before the exchange will need to be greater than or equal to the amount you pay on a total hourly basis after the exchange.\", 'Yes, you can enable Multi-Attach on an EBS Provisioned IOPS io1 volume to allow a volume to be concurrently attached to up to sixteen Nitro-based EC2 instances within the same Availability Zone. For more information on Amazon EBS Multi-Attach, see the EBS product page.', 'Lambda@Edge is optimized for latency-sensitive use cases where your end viewers are distributed globally. All the information you need to make a decision should be available at the CloudFront edge, within the function and the request. This means that use cases where you are looking to make decisions on how to serve content based on user characteristics (e.g., location, client device, etc.) can now be executed and served close to your users without having to be routed back to a centralized server. ', 'Yes, you cannot purchase your own listed RIs, including those in any of your linked accounts (via Consolidated Billing).', 'You can start with either an AWS provided base images for Lambda or by using one of your preferred community or private enterprise images. Then, simply use Docker CLI to build the image, upload it to Amazon ECR, and then create the function by using all familiar Lambda interfaces and tools, such as the AWS Management Console, the AWS CLI, the AWS SDK, AWS SAM, and AWS CloudFormation. ', 'S3 Multi-Region Access Points accelerate and simplify storage for your multi-region applications. By dynamically routing S3 requests made to a replicated data set, S3 Multi-Region Access Points reduce request latency, so that applications run up to 60% faster. S3 Multi-Region Access Points can also help you build resilient, multi-region and multi-account applications that are more protected against accidental or unauthorized data deletion. With S3 Multi-Region Access Points, you are able to take advantage of the global infrastructure of AWS while maintaining a simple region-agnostic architecture for your applications.', 'The storage capacity allocated to your DB Instance can be increased while maintaining DB Instance availability. However, when you decide to scale the compute resources available to your DB instance up or down, your database will be temporarily unavailable while the DB instance class is modified. This period of unavailability typically lasts only a few minutes, and will occur during the maintenance window for your DB Instance, unless you specify that the modification should be applied immediately. ', 'No, Amazon RDS Blue/Green Deployments do not support Global Databases, Amazon RDS Proxy, cross-Region read replicas, or cascaded read replicas. ', 'Yes, all existing features and AMIs supported on previous generation instances will be supported as we migrate these instances to AWS Nitro System.', 'Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.', 'How can I manage my AWS Lambda functions? ', 'M6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. M6g instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. Additionally, options with local NVMe instance storage are also available through the M6gd instance types.', 'There is no limit specific for Cluster Compute Instances. For Cluster GPU Instances, you can launch 2 Instances on your own. If you need more capacity, please complete the Amazon EC2 instance request form (selecting the appropriate primary instance type).', 'With Amazon S3 Lifecycle policies, you can configure your objects to be migrated from the S3 Standard storage class to S3 Standard-IA or S3 One Zone-IA and/or archived to S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, or S3 Glacier Deep Archive storage classes.   You can also specify an S3 Lifecycle policy to delete objects after a specific period of time. You can use this policy-driven automation to quickly and easily reduce storage costs as well as save time. In each rule you can specify a prefix, a time period, a transition to S3 Standard-IA, S3 One Zone-IA, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, S3 Glacier Deep Archive, and/or an expiration. For example, you could create a rule that archives into S3 Glacier Flexible Retrieval all objects with the common prefix logs/ 30 days from creation and expires these objects after 365 days from creation.   You can also create a separate rule that only expires all objects with the prefix backups/ 90 days from creation. S3 Lifecycle policies apply to both existing and new S3 objects, helping you optimize storage and maximize cost savings for all current data and any new data placed in S3 without time-consuming manual data review and migration.   Within a lifecycle rule, the prefix field identifies the objects subject to the rule. To apply the rule to an individual object, specify the key name. To apply the rule to a set of objects, specify their common prefix (e.g. logs/). You can specify a transition action to have your objects archived and an expiration action to have your objects removed. For time period, provide the creation date (e.g. January 31, 2015) or the number of days from creation date (e.g. 30 days) after which you want your objects to be archived or removed. You may create multiple rules for different prefixes.', 'You can deploy and manage your serverless applications using the AWS Serverless Application Model (AWS SAM). AWS SAM is a specification that prescribes the rules for expressing serverless applications on AWS. This specification aligns with the syntax used by AWS CloudFormation today and is supported natively within AWS CloudFormation as a set of resource types (referred to as serverless resources). These resources make it easier for AWS customers to use CloudFormation to configure and deploy serverless applications using existing CloudFormation APIs. ', 'AWS Lambda allows you to run your functions on either x86-based or Arm-based processors. AWS Graviton2 processors are custom built by Amazon Web Services using 64-bit Arm Neoverse cores to deliver increased price performance for your cloud workloads. Customers get the same advantages of AWS Lambda, running code without provisioning or managing servers, automatic scaling, high availability, and only paying for the resources you consume. ', 'When you launch resources in a default VPC, you can benefit from the advanced networking functionalities of Amazon VPC (EC2-VPC) with the ease of use of Amazon EC2 (EC2-Classic). You can enjoy features such as changing security group membership on the fly, security group egress filtering, multiple IP addresses, and multiple network interfaces without having to explicitly create a VPC and launch instances in the VPC. ', 'High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for low latency networking.', 'The IAM policy simulator evaluates policies you choose and determines the effective permissions for each of the actions you specify. Use the policy simulator to test and troubleshoot identity-based and resource-based policies, IAM permissions boundaries, and SCPs. For more information, see Testing IAM policies with the IAM policy simulator.', 'No. Spot fleet requests allow you to place multiple Spot Instance requests simultaneously, and are subject to the same availability and prices as a single Spot Instance request. For example, if no resources are available for the instance types listed in your Spot Fleet request, we may be unable to fulfill your request partially or in full. We recommend that you to include all the possible instance types and availability zones that are suitable for your workloads in the Spot Fleet.', 'There are two cases where developers would choose EI over Inf1 instances: (1) if you need different CPU and memory sizes than what Inf1 offers, then you can use EI to attach acceleration to the EC2 instance with the right mix of CPU and memory for your application (2) if your performance requirements are significantly lower than what the smallest Inf1 instance provides, then using EI could be a more cost effective choice. For example, if you only need 5 TOPS, enough for processing up to 6 concurrent video streams, then using the smallest slice of EI with a C5.large instance could be up to 50% cheaper than using the smallest size of an Inf1 instance.', \"Use Savings Plans or Regional RIs to reduce your bill while committing to a one- or three-year term. Savings Plans offer significant savings over On-Demand, just like EC2 RIs, but automatically reduce customers' bills on compute usage across any AWS Region, even as usage changes. Use On-Demand Capacity Reservations if you need the additional confidence in your ability to launch instances. On-Demand Capacity Reservations can be created for any duration and can be managed independently of your Savings Plans or RIs. If you have Savings Plans or Regional RIs, they will automatically apply to matching On-Demand Capacity Reservations. This gives you the flexibility to selectively add On-Demand Capacity Reservations to a portion of your instance footprint and still reduce your bill for that usage.\", 'You can sell an RI for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term RI.', 'You can view all the system metrics and process information for your Amazon RDS DB Instances in a graphical format on the console. You can manage which metrics you want to monitor for each instance and customize the dashboard according to your requirements. ', 'Metrics are received and aggregated at 1 minute intervals.', 'The minimum allocation period for an EC2 Mac instance Dedicated Host is 24 hours. After the allocation period has exceeded 24 hours, first stop or terminate the instance running on the host, then release the host using the aws ec2 release-hosts CLI command or the AWS Management Console.', 'The c4.8xlarge instance type provides the ability for an operating system to control processor C-states and P-states. This feature is currently available only on Linux instances. You may want to change C-state or P-state settings to increase processor performance consistency, reduce latency, or tune your instance for a specific workload. By default, Amazon Linux provides the highest-performance configuration that is optimal for most customer workloads; however, if your application would benefit from lower latency at the cost of higher single- or dual-core frequencies, or from lower-frequency sustained performance as opposed to bursty Turbo Boost frequencies, then you should consider experimenting with the C-state or P-state configuration options that are available to these instances. For additional information on this feature, see the Amazon EC2 User Guide section on Processor State Control.', 'Provide notification to your regulator or Designated Examining Authority (DEA) of your choice to use Amazon S3 for electronic storage along with a copy of the Cohasset Assessment. For the purposes of these requirements, AWS is not a designated third party (D3P). Be sure to select a D3P and include this information in your notification to your DEA.', 'S3 Access Grants supports two kinds of identities: enterprise user or group identities from AWS Identity Center, and AWS IAM principals including IAM users and roles. When you use S3 Access Grants with AWS Identity Center, you can define data permissions on the basis of directory group memberships. AWS Identity Center is an AWS service that connects to commonly-used identity providers, including Entra ID, Okta, Ping, and others. In addition to supporting directory identities via AWS Identity Center, S3 Access Grants also supports permission rules for AWS IAM principal including IAM users and roles. This is for use cases where you either manage a custom identity federation not through AWS Identity Center but via IAM and SAML assertion (example implementation), or manage application identities based on IAM principals, and still would like to use S3 Access Grants due to its scalability and auditability.', 'Code Signing for AWS Lambda offers trust and integrity controls that enable you to verify that only unaltered code from approved developers is deployed in your Lambda functions. You can use AWS Signer, a fully-managed code signing service, to digitally sign code artifacts and configure your Lambda functions to verify the signatures at deployment. Code Signing for AWS Lambda is currently only available for functions packaged as ZIP archives. ', 'How can I manage my AWS Lambda functions? ', 'ENA Express works best for applications requiring high, single-flow throughput, like distributed storage systems and live media encoding. These workloads require high single flow bandwidth and low tail latency.', 'AWS Lambda functions powered by AWS Graviton2 processors are 20% cheaper compared to x86-based Lambda functions. The Lambda free tier applies to AWS Lambda functions powered by x86 and Arm-based architectures. ', 'Amazon EC2 T4g instances are the next-generation of general purpose burstable instances powered by Arm-based AWS Graviton2 processors. T4g instances deliver up to 40% better price performance over T3 instances. They are built on the AWS Nitro System, a combination of dedicated hardware and Nitro hypervisor.', 'Yes. Amazon EKS performs managed, in-place cluster upgrades for both Kubernetes and Amazon EKS platform versions. This simplifies cluster operations and lets you take advantage of the latest Kubernetes features, as well as the updates to Amazon EKS configuration and security patches.', \"Yes. Amazon S3's durability system does not protect against accidental or malicious deletes. S3 relies on customers to decide what data they want to keep, what data they want to get rid of, and what optional controls they need to protect against deletes that are incorrect, either due to accidents or malice. When you tell Amazon S3 to delete data, that data is immediately deleted, and it cannot be recovered by AWS. Honoring a delete request in this way is an important characteristic of the service.\", 'You can request to launch Spot Instances with tags via Spot Fleet. The Fleet by itself cannot be tagged.', 'To use Lambda@Edge, you just upload your code to AWS Lambda and associate a function version to be triggered in response to Amazon CloudFront requests. Your code must satisfy the Lambda@Edge service limits. Lambda@Edge supports Node.js and Python for global invocation by CloudFront events at this time. Learn more in our documentation. ', 'You can use the Amazon S3 console, AWS API, or AWS CLI to enable S3 Object Lock while creating a new bucket or to configure S3 Object Lock on existing buckets. To enable S3 Object Lock on existing buckets, you can use the Amazon S3 console to edit S3 Object Lock settings in the bucket Properties tab the PutObjectLockConfiguration AWS API, or the AWS CLI. Once S3 Object Lock is enabled, you can set a default bucket level retention mode and time that will be applicable to all new objects uploaded to the bucket. For more information see the documentation on configuring S3 Object Lock using the S3 console, using the AWS API, and using the AWS CLI.', 'The following AMIs are supported: Amazon Linux 2, Ubuntu 18.04 or newer, Red Hat Enterprise Linux 8.2 or newer, and SUSE Enterprise Server 15 or newer. Customers will find additional AMIs such as Fedora, Debian, NetBSD, and CentOS available through community AMIs and the AWS Marketplace. For containerized applications, Amazon ECS and EKS optimized AMIs are available as well.', 'AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). AWS Fargate makes it easy to focus on building your applications by eliminating the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design. ', 'In some cases, we may deprecate specific major or minor versions without prior notice, such as when we discover a version does not meet our high quality, performance, or security bar. In the unlikely event that such cases occur, Amazon RDS will discontinue the creation of new database instances and clusters with these versions. Existing customers may continue to be able to run their databases. Specific circumstances may dictate different timelines depending on the issue being addressed. ', 'A1 instances are EBS-optimized by default and offer up to 3,500 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. A1 instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. A1 instances will not support the blkfront interface.', 'Availability Zones are engineered to provide low latency network connectivity to other Availability Zones in the same Region. In addition, you may want to consider architecting your application and other AWS resources with redundancy across multiple Availability Zones so your application will be resilient in the event of an Availability Zone failure. Multi-AZ deployments address this need for the database tier without administration on your part. ', 'If your DB instance is not in a VPC, you can use the AWS Management Console to easily move your DB instance into a VPC. See the Amazon RDS User Guide for more details. You can also take a snapshot of your DB Instance outside VPC and restore it to VPC by specifying the DB Subnet Group you want to use. Alternatively, you can perform a  Restore to Point in Time  operation as well. ', \"Amazon S3 Transfer Acceleration creates fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. S3 Transfer Acceleration leverages Amazon CloudFront's globally distributed AWS Edge locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.\", 'You can enable code signing by creating a Code Signing Configuration through the AWS Management Console, the Lambda API, the AWS CLI, AWS CloudFormation, and AWS SAM. Code Signing Configuration helps you specify the approved signing profiles and configure whether to warn or reject deployments if signature checks fail. Code Signing Configurations can be attached to individual Lambda functions to enable the code signing feature. Such functions now start verifying signatures at deployment. ', 'Cluster Compute Instances combine high compute resources with high performance networking for HPC applications and other demanding network-bound applications. Cluster Compute Instances provide similar functionality to other Amazon EC2 instances but have been specifically engineered to provide high performance networking.', 'Yes. The Hardware Development Kit (HDK) includes simulation tools and simulation models for developers to simulate, debug, build, and register their acceleration code. The HDK includes code samples, compile scripts, debug interfaces, and many other tools you will need to develop the FPGA code for your F1 instances. You can use the HDK either in an AWS provided AMI, or in your on-premises development environment. These models and scripts are available, publicly with an AWS account.', 'Optimize CPUs gives you greater control of your EC2 instances on two fronts. First, you can specify a custom number of vCPUs when launching new instances to save on vCPU-based licensing costs. Second, you can disable Intel Hyper-Threading Technology (Intel HT Technology) for workloads that perform well with single-threaded CPUs, such as certain HPC applications.', 'For Amazon S3 bucket notifications and custom events, AWS Lambda will attempt execution of your function three times in the event of an error condition in your code or if you exceed a service or resource limit. For ordered event sources that AWS Lambda polls on your behalf, such as Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution in the event of a developer code error until the data expires. You can monitor progress through the Amazon Kinesis and Amazon DynamoDB consoles and through the Amazon CloudWatch metrics that AWS Lambda generates for your function. You can also set Amazon CloudWatch alarms based on error or execution throttling rates. ', \"IAM Access Analyzer custom policy checks validate that IAM policies adhere to your security standards ahead of deployments. Custom policy checks use the power of automated reasoning provable security assurance backed by mathematical proof  to enable security teams to proactively detect nonconformant updates to policies. For example, IAM policy changes that are more permissive than their previous version. Security teams can use these checks to streamline their reviews, automatically approving policies that conform with their security standards, and inspecting more deeply when they don't. This new kind of validation provides higher security assurance in the cloud. Security and development teams can automate policy reviews at scale by integrating these custom policy checks into the tools and environments where developers author their policies, such as their CI/CD pipelines.\", 'To sign up for Amazon EC2, select the Sign up for This Web Service button on the Amazon EC2 detail page. You must have an AWS account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 signup process. After signing up, please refer to the Amazon EC2 documentation, which includes our Getting Started Guide.', 'Yes. Savings Plans or Regional RI discounts apply to On-Demand Capacity Reservations. AWS Billing automatically applies the discount when the attributes of an On-Demand Capacity Reservation match the attributes of a Savings Plan or Regional RI. When an On-Demand Capacity Reservation is used by an instance, you are only charged for the instance (with Savings Plan or RI discounts applied). Discounts are preferentially applied to instance usage before covering unused On-Demand Capacity Reservations.', \"DB instances are simple to create using either the AWS Management Console, Amazon RDS APIs, or AWS Command Line Interface. To launch a DB instance using the AWS Management Console, click RDS and then the  Launch DB Instance  button on the Instances tab. From there, you can specify the parameters for your DB instance, including DB engine and version, license model, instance type, storage type and amount, and primary user credentials. You also have the ability to change your DB instance's backup retention policy, preferred backup window, and scheduled maintenance window. Alternatively, you can create your DB instance using the CreateDBInstance API or create-db-instance command. \", 'When you configure an Amazon S3 bucket to send messages to an AWS Lambda function, a resource policy rule will be created that grants access. Visit the Lambda Developer Guide to learn more about resource policies and access controls for Lambda functions. ', 'S3 Access Grants offers three access levels: READ, WRITE, and READWRITE. READ allows you to view and retrieve objects from S3. WRITE allows you to write to and delete from S3. READWRITE allows you to do both READ and WRITE.', 'You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update. ', 'Consider using Amazon RDS On-Demand Instances for flexibility or Amazon RDS Aurora Serverless for automatic cost optimization based on actual usage.', 'Amazon EKS add-ons provides one-click installation and management of Kubernetes operational software. Go from cluster creation to running applications in a single command, while easily keeping the operational software required for your cluster up to date. This ensures your Kubernetes clusters are secure and stable and reduces the amount of work needed to start and manage production-ready Kubernetes clusters on AWS.', 'C5 instances will support only NVMe EBS device model. EBS volumes attached to C5 instances will appear as NVMe devices. NVMe is a modern storage interface that provides latency reduction and results in increased disk I/O and throughput.', \"PostgreSQL extensions are executed in the same process space for high performance. However, extensions might have software defects that can crash the database.  TLE for PostgreSQL offers multiple layers of protection to mitigate this risk. TLE is designed to limit access to system resources. The rds_superuser role can determine who is permitted to install specific extensions. However, these changes can only be made through the TLE API. TLE is designed to limit the impact of an extension defect to a single database connection. In addition to these safeguards, TLE is designed to provide DBAs in the rds_superuser role fine-grained, online control over who can install extensions and they can create a permissions model for running them.  Only users with sufficient privileges will be able to run and create using the  CREATE EXTENSION  command on a TLE extension. DBAs can also allow-list  PostgreSQL hooks  required for more sophisticated extensions that modify the database's internal behavior and typically require elevated privilege. \", 'Amazon S3 Request pricing is summarized on the Amazon S3 pricing page.', 'VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.', 'vCPU-based instance limits are available in all commercial AWS Regions.', 'Use a mix of On-Demand and Spot Instances with Auto Scaling. Auto Scaling can automatically replace Spot Instances that are interrupted, ensuring your application remains available.', 'There are several factors to consider based on your specific application. For instance, you may want to store your data in a Region that is near your customers, your data centers, or other AWS resources to reduce data access latencies. You may also want to store your data in a Region that is remote from your other operations for geographic redundancy and disaster recovery purposes. You should also consider Regions that let you address specific legal and regulatory requirements and/or reduce your storage costs you can choose a lower priced Region to save money. For S3 pricing information, visit the Amazon S3 pricing page.', 'When Amazon RDS Blue/Green Deployments initiate a switchover, they block writes to both the blue and green environments, until switchover is complete. During switchover, the staging environment, or green environment, catches up with the production system, ensuring data is consistent between the staging and production environment. Once the production and staging environment are in complete sync, Blue/Green Deployments promote the staging environment as the production environment by redirecting traffic to the newly promoted production environment. Blue/Green Deployments are designed to enable writes on the green environment after switchover is complete, ensuring zero data loss during the switchover process. ', 'In the case of hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shut down and RAM is cleared.', \"To access your file system, you mount the file system on an Amazon EC2 Linux-based instance using the standard Linux mount command and the file system's DNS name. Once you've mounted, you can work with the files and directories in your file system just like you would with a local file system.\", 'The code you run on AWS Lambda is uploaded as a Lambda function. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a stateless style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones. ', 'Each AWS Lambda function runs in its own isolated environment, with its own resources and file system view. AWS Lambda uses the same techniques as Amazon EC2 to provide security and separation at the infrastructure and execution levels. ', 'Yes. All data stored in ephemeral storage is encrypted at rest with a key managed by AWS. ', 'AWS Lambda offers an easy way to accomplish many activities in the cloud. For example, you can use AWS Lambda to build mobile back-ends that retrieve and transform data from Amazon DynamoDB, handlers that compress or transform objects as they are uploaded to Amazon S3, auditing and reporting of API calls made to any Amazon Web Service, and server-less processing of streaming data using Amazon Kinesis. ', 'There are no additional charges for using Amazon S3 for event notifications. You pay only for use of Amazon SNS or Amazon SQS to deliver event notifications, or for the cost of running an AWS Lambda function. Visit the Amazon SNS, Amazon SQS, or AWS Lambda pricing pages to view the pricing details for these services.', 'Yes, A1 instances are powered by the AWS Nitro System, a combination of dedicated hardware and Nitro hypervisor.', \"You pay the Spot price that's in effect at the beginning of each instance-hour for your running instance. If Spot price changes after you launch the instance, the new price is charged against the instance usage for the subsequent hour.\", 'AWS Lambda now enables you to package and deploy functions as container images. Customers can leverage the flexibility and familiarity of container tooling, and the agility and operational simplicity of AWS Lambda to build applications. ', 'IAM provides fine-grained access control across all of AWS. With IAM, you can control access to services and resources under specific conditions. Use IAM policies to manage permissions for your workforce and systems to ensure least privilege. IAM is offered at no additional charge. For more information, see What is IAM?', 'Our system automatically optimizes which instances are charged at the discounted rate to ensure that the consolidated accounts always pay the lowest amount. If you own RIs that apply to an AZ, then only the account which owns the RI will receive the capacity reservation. However, the discount will automatically apply to usage in any account across your consolidated billing family.', 'Yes, we plan to offer Intel and AMD CPU powered instances in the future as part of the C6 instance families.', 'Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements.', 'No, snapshots can be done in real time while the volume is attached and in use. However, snapshots only capture data that has been written to your Amazon EBS volume, which might exclude any data that has been locally cached by your application or OS. In order to ensure consistent snapshots on volumes attached to an instance, we recommend cleanly detaching the volume, issuing the snapshot command, and then reattaching the volume. For Amazon EBS volumes that serve as root devices, we recommend shutting down the machine to take a clean snapshot.', 'The total volume of data and number of objects you can store in Amazon S3 are unlimited. Individual Amazon S3 objects can range in size from a minimum of 0 bytes to a maximum of 5 TB. The largest object that can be uploaded in a single PUT is 5 GB. For objects larger than 100 MB, customers should consider using the multipart upload capability.', 'You can use Auto Scaling features with Spot Fleet such as target tracking, health checks, CloudWatch metrics, etc., and can attach instances to your Elastic load balancers (both classic and application load balancers). Elastic MapReduce has a feature named Instance fleets that provides capabilities similar to Spot Fleet.', 'To sign up for Amazon EC2, select the Sign up for This Web Service button on the Amazon EC2 detail page. You must have an AWS account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 signup process. After signing up, please refer to the Amazon EC2 documentation, which includes our Getting Started Guide.', 'Spot blocks are designed not to be interrupted and will run continuously for the duration you select, independent of Spot market price. In rare situations, Spot blocks may be interrupted due to AWS capacity needs. In these cases, we will provide a two-minute warning before we terminate your instance (termination notice), and you will not be charged for the affected instance(s).', 'For Amazon S3 bucket notifications and custom events, AWS Lambda will attempt execution of your function three times in the event of an error condition in your code or if you exceed a service or resource limit. For ordered event sources that AWS Lambda polls on your behalf, such as Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution in the event of a developer code error until the data expires. You can monitor progress through the Amazon Kinesis and Amazon DynamoDB consoles and through the Amazon CloudWatch metrics that AWS Lambda generates for your function. You can also set Amazon CloudWatch alarms based on error or execution throttling rates. ', 'AWS offers eligible customers free data transfer out to the internet when they move all of their data off of AWS, in accordance with the process below.', 'EC2 Capacity Blocks are available in cluster sizes of 1, 2, 4, 8, 16, 32, and 64 instances, and they can be reserved for up to 14 days in one-day multiples.', 'Yes. Enable automatic backups on your source DB Instance before adding read replicas by setting the backup retention period to a value other than 0. Backups must remain enabled for read replicas to work. ', 'Provisioned Concurrency gives you greater control over the performance of your serverless applications. When enabled, Provisioned Concurrency keeps functions initialized and hyper-ready to respond in double-digit milliseconds. ', 'You grant permissions to your Lambda function to access other resources using an IAM role. AWS Lambda assumes the role while executing your Lambda function, so you always retain full, secure control of exactly which AWS resources it can use. Visit Setting up AWS Lambda to learn more about roles. ', 'Amazon S3 is object storage built to store and retrieve any amount of data from anywhere. S3 is a simple storage service that offers industry leading durability, availability, performance, security, and virtually unlimited scalability at very low costs.', 'EC2 Mac instances are bare metal instances and do not use the Nitro hypervisor. You can install and run a type-2 virtualization layer on x86-based EC2 Mac instances to get access to macOS High Sierra, Sierra, or older macOS versions. On EC2 M1 Mac instances, as macOS Big Sur is the first macOS version to support Apple Silicon, older macOS versions will not run even under virtualization.', 'S3 Storage Class Analysis provides recommendations for an optimal storage class by creating object age groups based on object-level access pattern within an individual bucket/prefix/tag for the previous 30-90 days. S3 Storage Lens provides daily organization level recommendations on ways to improve cost efficiency and apply data protection best practices, with additional granular recommendations by account, region, storage class, bucket, S3 Storage Lens group, or prefix (available with S3 Storage Lens advanced metrics). You can also use custom filters with S3 Storage Lens groups to visualize your storage based on object age and inform your storage archival strategy.', 'AWS offers eligible customers free data transfer out to the internet when they move all of their data off of AWS, in accordance with the process below.', 'You can purchase up to 40 reserved DB instances. If you wish to run more than 40 DB instances, please complete the Amazon RDS DB Instance request form. ', 'Use S3 bucket policies and IAM policies to define fine-grained access control for different folders within your S3 bucket.', 'X2gd instances are suitable for Arm-compatible memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers. X2gd instances offer customers the lowest cost per gigabyte of memory within EC2, with sizes up to 1 TiB. X2iezn, X2idn, X2iedn, X1, and X1e instances use x86 processors and are suitable for memory-intensive enterprise-class, scale-up workloads such as Windows workloads, in-memory databases (e.g. SAP HANA), and relational databases (e.g. OracleDB). Customers can leverage the x86-based X instances for larger memory sizes up to 4 TiB. R6g and R6gd instances are suitable for workloads such as web applications, databases, and search indexing queries that need more vCPUs during times of heavy data processing. Customers running memory bound workloads that need less than 1 TiB memory and have dependency on x86 instruction set such as Windows applications, and applications like Oracle or SAP can leverage R5 instances and R6 instances.', 'Start with Amazon EC2. It offers a wide range of pre-configured Amazon Machine Images (AMIs), making it easy to launch instances with different operating systems and software stacks.', 'You are billed at standard Amazon RDS prices for instance hours beyond what the Free Tier provides. See the Amazon RDS pricing page for details. ', 'AWS Fargate offers a flexible integration model inclusive of both first party AWS services and third party Amazon Partner Network (APN) solutions. The common integration mechanism is to run a sidecar container within a AWS Fargate task that can interact with the primary application container, for example a runtime security agent or log router that interacts with the primary application and then ships data to a centralized system for analysis and review. ', 'Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements.', 'Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance or burstable performance; Compute Optimized instances have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerated Computing instances use hardware accelerators, or co-processors, to perform functions such as floating point number calculations, graphics processing, or data pattern matching, more efficiently than is possible in software running on CPUs; Storage Optimized Instances provide low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, as well as dense HDD-storage instances, which provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size.', 'Yes. Enable automatic backups on your source DB Instance before adding read replicas by setting the backup retention period to a value other than 0. Backups must remain enabled for read replicas to work. ', \"Yes, simply specify the AMI you'd like to use in each launch specification you provide in your Spot Fleet request.\", 'G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.', 'You can sell an RI for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term RI.', 'Amazon EKS extended support for Kubernetes versions lets you use a Kubernetes minor version for up to 26 months from the time the version is generally available from Amazon EKS. Amazon EKS versions in extended support receive ongoing security patches for the Kubernetes control plane managed by Amazon EKS. Additionally, Amazon EKS will release critical patches for the Amazon VPC CNI, kube-proxy, and CoreDNS add-ons, AWS-published EKS Optimized Amazon Machine Images (AMIs) for Amazon Linux, Bottlerocket, Windows, and EKS Fargate nodes. AWS backs all Amazon EKS versions in both standard and extended support with full technical support. Extended support for Kubernetes versions is available in all AWS Regions where Amazon EKS is available, including AWS GovCloud (US) Regions. Learn more about the Amazon EKS version support policy in the Amazon EKS documentation.', 'The Amazon RDS maintenance window is your opportunity to control when DB instance modifications, database engine version upgrades, and software patching occurs, in the event they are requested or required. If a maintenance event is scheduled for a given week, it will be initiated during the maintenance window you identify. Maintenance events that require Amazon RDS to take your DB instance offline are scale compute operations (which generally take only a few minutes from start-to-finish), database engine version upgrades, and required software patching. Required software patching is automatically scheduled only for patches that are security and durability related. Such patching occurs infrequently (typically once every few months) and should seldom require more than a fraction of your maintenance window. If you do not specify a preferred weekly maintenance window when creating your DB instance, a 30-minute default value is assigned. If you wish to modify when maintenance is performed on your behalf, you can do so by modifying your DB instance in the AWS Management Console, the ModifyDBInstance API, or the modify-db-instance command. Each of your DB instances can have different preferred maintenance windows, if you so choose. Running your DB instance as a Multi-AZ deployment can further reduce the impact of a maintenance event. Please refer to the Amazon RDS User Guide for more information on maintenance operations. ', 'P3 instances use GPUs to accelerate numerous deep learning systems and applications including autonomous vehicle platforms, speech, image, and text recognition systems, intelligent video analytics, molecular simulations, drug discovery, disease diagnosis, weather forecasting, big data analytics, financial modeling, robotics, factory automation, real-time language translation, online search optimizations, and personalized user recommendations, to name just a few.', 'Amazon RDS will automatically failover without user intervention under a variety of failure conditions. In addition, Amazon RDS provides an option to initiate a failover when rebooting your instance. You can access this feature via the AWS Management Console or when using the RebootDBInstance API call. ', 'After launching your instance and receiving an instance id, you can use the following command to poll the instance and determine when it is ready for SSH access. Connecting over SSH to EC2 Mac instances follows the same process as connecting to other EC2 instances, such as those running Linux or Windows. To support connecting to your instance using SSH, launch the instance using a key pair and a security group that allows SSH access. Provide the .pem file for the key pair when you connect to the instance. For more information, please see the documentation.', 'C6g instances deliver significant price performance benefits for compute-intensive workloads such as high performance computing (HPC), batch processing, ad serving, video encoding, gaming, scientific modelling, distributed analytics, and CPU-based machine learning inference. Customers deploying applications built on open source software across C instances family will find the C6g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation.', 'If you want to take advantage of the capacity reservation, then you should buy an RI in a specific AZ.', 'You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update. ', \"P4d instances are deployed in hyperscale clusters called EC2 UltraClusters. Each EC2 UltraCluster is comprised of more than 4,000 NVIDIA A100 Tensor Core GPUs, Petabit-scale networking, and scalable low latency storage with FSx for Lustre. Each EC2 UltraCluster is one of the world's top supercomputers. Anyone can easily spin up P4d instances in EC2 SuperClusters. For additional help, contact us.\", 'You can use AWS CloudWatch Lambda Insight metrics to monitor your ephemeral storage usage. To learn more, see the AWS CloudWatch Lambda Insights documentation. ', 'The maximum allowed initialization duration for Lambda SnapStart will match the execution timeout duration you have configured for your function. The maximum configurable execution timeout limit for a function is 15 minutes. ', \"Amazon S3's designed for durability is a function of storage device failure rates and the rate at which S3 can detect failure, and then re-replicate data on those devices. S3 has end-to-end integrity checking on every object upload and verifies that all data is correctly and redundantly stored across multiple storage devices before it considers your upload to be successful. Once your data is stored in S3, S3 continuously monitors data durability over time with periodic integrity checks of all data at rest. S3 also actively monitors the redundancy of your data to help verify that your objects are able to tolerate the concurrent failure of multiple storage devices.\", 'The code you run on AWS Lambda is uploaded as a Lambda function. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a stateless style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones. ', 'How can I manage my AWS Lambda functions? ', 'Use Amazon S3 Glacier for data archiving. It provides low-cost storage with retrieval times ranging from minutes to hours.', 'No, we do not support multi-region Fleet requests.', \"EFA devices provide all ENA devices' functionalities plus a new OS bypass hardware interface that allows user-space applications to communicate directly with the hardware-provided reliable transport functionality. Most applications will use existing middleware, such as the MPI, to interface with EFA. AWS has worked with a number of middleware providers to ensure support for the OS bypass functionality of EFA. Please note that communication using the OS bypass functionality is limited to instances within a single subnet of a virtual private cloud (VPC).\", 'AWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers. AWS Fargate is compatible with both Amazon ECS and Amazon EKS. AWS Fargate makes it easy to scale and manage cloud applications by shifting as much management of the underlying infrastructure resources to AWS so development teams can focus on writing code that solve business problems. Shifting tasks such as server management, resource allocation, and scaling to AWS does not only improve your operational posture, but also accelerates the process of going from idea to production on the cloud and lowers the total cost of ownership (TCO). With multiple CPU architectures and operating systems supported, you can enjoy the serverless benefits of cost, agility and scale across a wide variety of applications. ', \"Amazon EKS works by provisioning (starting) and managing the Kubernetes control plane and worker nodes for you. At a high level, Kubernetes consists of two major components: a cluster of 'worker nodes' running your containers, and the control plane managing when and where containers are started on your cluster while monitoring their status.\", 'New AWS accounts receive 12 months of AWS Free Tier access. Please see the AWS Free Tier FAQs for more information. ', 'Amazon S3 Data Transfer Out pricing is summarized on the Amazon S3 pricing page. For Amazon S3, this charge applies whenever data is read from any of your buckets from a location outside of the given Amazon S3 Region.', 'You can now use an Availability Zone ID (AZ ID) instead of an AZ name. An AZ ID is a static reference and provides a consistent way of identifying the location of a resource across all your accounts. This makes it easier for you to provision resources centrally in a single account and share them across multiple accounts.', \"Amazon RDS Proxy addresses a number of use cases related to scalability, availability, and security of your applications, including: Applications with unpredictable workloads: Applications that support highly variable workloads may attempt to open a burst of new database connections. Amazon RDS Proxy's connection governance allows you to gracefully scale applications dealing with unpredictable workloads by efficiently reusing database connections. First, RDS Proxy enables multiple application connections to share a database connection for efficient use of database resources. Second, RDS Proxy allows you to maintain predictable database performance by regulating the number of database connections that are opened. Third, RDS Proxy removes requests that cannot be served to preserve the overall performance and availability of the application. Applications that frequently open and close database connections: Applications built on technologies such as Serverless, PHP, or Ruby on Rails may open and close database connections frequently to serve application requests. Amazon RDS Proxy maintains a pool of database connections to avoid unnecessary stress on database compute and memory for establishing new connections. Applications that keep connections open but idle: Applications in industries such as SaaS or eCommerce may keep database connections idling to minimize the response time when a customer reengages. Instead of overprovisioning databases to support mostly idling connections, you can use Amazon RDS Proxy to hold idling connections while only establishing database connections as required to optimally serve active requests. Applications requiring availability through transient failures: With Amazon RDS Proxy, you can build applications that can transparently tolerate database failures without needing to write complex failure handling code. RDS Proxy automatically routes traffic to a new database instance while preserving application connections. RDS Proxy also bypasses Domain Name System (DNS) caches to reduce failover times by up to 66% for Amazon RDS and Aurora Multi-AZ databases. During database failovers, the application may experience increased latencies and ongoing transactions may have to be retried. Improved security and centralized credentials management: Amazon RDS Proxy aids you in building more secure applications by giving you a choice to enforce IAM based authentication with relational databases. RDS Proxy also enables you to centrally manage database credentials through AWS Secrets Manager. \", 'Generate pre-signed URLs using AWS SDKs or the AWS Management Console to grant temporary access to your S3 bucket without sharing credentials.', 'Store your Amazon RDS backups in Amazon S3 for long-term data retention, ensuring durability and easy retrieval.', 'AWS Lambda is priced on a pay-per-use basis. Please see the AWS Lambda pricing page for details. ', 'Consider using Amazon RDS On-Demand Instances for flexibility or Amazon RDS Aurora Serverless for automatic cost optimization based on actual usage.', 'If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, you will not be charged for that usage. However, if you stop or terminate the Spot instance yourself, you will be charged to the nearest second. If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows or Red Hat Enterprise Linux (RHEL) and you stop or terminate the Spot instance yourself, you will be charged for an entire hour.', 'You can use Amazon Step Functions to coordinate multiple invoking Lambda functions. You can invoke multiple Lambda functions serially, passing the output of one to the other, or in parallel. See our documentation for more details. ', 'No. You can only use the three pre-defined access levels (READ/WRITE/READWRITE) that S3 Access Grants offers.', 'You can enable Lambda functions to access resources in your VPC by specifying the subnet and security group as part of your function configuration. Lambda functions configured to access resources in a particular VPC will not have access to the internet as a default configuration. To grant internet to these functions, use internet gateways. By default, Lambda functions communicate with resources in a dual-stack VPC over IPv4. You can configure your functions to access resources in a dual-stack VPC over IPv6. For more details on Lambda functions configured with VPC, see Lambda Private Networking with VPC. ', \"AWS Graviton processors are custom designed by AWS utilizing Amazon's extensive expertise in building platform solutions for cloud applications running at scale. These processors are based on the 64-bit Arm instruction set and feature Arm Neoverse cores as well as custom silicon designed by AWS. The cores operate at a frequency of 2.3 GHz.\", 'Use Amazon S3, a scalable object storage service designed for storing and retrieving any amount of data.', 'No, EBS snapshots are only available through the Amazon EC2 APIs.', 'Yes. All data stored in ephemeral storage is encrypted at rest with a key managed by AWS. ', \"From the AWS Lambda console, you can select a function and associate it with notifications from an Amazon S3 bucket. Alternatively, you can use the Amazon S3 console and configure the bucket's notifications to send to your AWS Lambda function. This same functionality is also available through the AWS SDK and CLI. \", 'You can choose to have your Spot instances terminated, stopped or hibernated upon interruption. Stop and hibernate options are available for persistent Spot requests and Spot Fleets with the maintain option enabled. By default, your instances are terminated.', 'Amazon EC2 instances within your VPC can access your file system directly. On-premises servers can mount your file systems via an AWS Direct Connect connection to your VPC.', 'How can I manage my AWS Lambda functions? ', 'S3 Access Grants supports two kinds of identities: enterprise user or group identities from AWS Identity Center, and AWS IAM principals including IAM users and roles. When you use S3 Access Grants with AWS Identity Center, you can define data permissions on the basis of directory group memberships. AWS Identity Center is an AWS service that connects to commonly-used identity providers, including Entra ID, Okta, Ping, and others. In addition to supporting directory identities via AWS Identity Center, S3 Access Grants also supports permission rules for AWS IAM principal including IAM users and roles. This is for use cases where you either manage a custom identity federation not through AWS Identity Center but via IAM and SAML assertion (example implementation), or manage application identities based on IAM principals, and still would like to use S3 Access Grants due to its scalability and auditability.', 'AWS Lambda allows you to run your functions on either x86-based or Arm-based processors. AWS Graviton2 processors are custom built by Amazon Web Services using 64-bit Arm Neoverse cores to deliver increased price performance for your cloud workloads. Customers get the same advantages of AWS Lambda, running code without provisioning or managing servers, automatic scaling, high availability, and only paying for the resources you consume. ', 'Combine Amazon S3 for static content storage with Amazon CloudFront for global content delivery and HTTPS support.', 'Lambda-based applications (also referred to as serverless applications) are composed of functions triggered by events. A typical serverless application consists of one or more functions triggered by events such as object uploads to Amazon S3, Amazon SNS notifications, or API actions. These functions can stand alone or leverage other resources such as DynamoDB tables or Amazon S3 buckets. The most basic serverless application is simply a function. ', 'By default, Amazon RDS enables automated backups of your DB instance with a 7-day retention period. If you would like to modify your backup retention period, you can do so using the RDS Console, the CreateDBInstance API (when creating a new DB Instance), or the ModifyDBInstance API (for existing instances). You can use these methods to change the RetentionPeriod parameter to any number from 0 (which will disable automated backups) to the desired number of days, up to 35. The value cannot be set to 0 if the DB instance is a source to Read Replicas. For more information on automated backups, please refer to the Amazon RDS User Guide. ', 'AWS Lambda now enables you to package and deploy functions as container images. Customers can leverage the flexibility and familiarity of container tooling, and the agility and operational simplicity of AWS Lambda to build applications. ', 'EC2 uses the scale shown below to compare different sizes within an instance family. In the case of instance size flexibility on RIs, this scale is used to apply the discounted rate of RIs to the normalized usage of the instance family. For example, if you have an m5.2xlarge RI that is scoped to a region, then your discounted rate could apply towards the usage of 1 m5.2xlarge or 2 m5.xlarge instances.', \"S3 Intelligent-Tiering is the first cloud storage that automatically reduces your storage costs on a granular object level by automatically moving data to the most cost-effective access tier based on access frequency, without performance impact, retrieval fees, or operational overhead. S3 Intelligent-Tiering delivers milliseconds latency and high throughput performance for frequently, infrequently, and rarely accessed data in the Frequent, Infrequent, and Archive Instant Access tiers. For a small monthly object monitoring and automation charge, S3 Intelligent-Tiering monitors the access pattern and moves the objects automatically from one tier to another. There are no retrieval charges in S3 Intelligent-Tiering, so you won't see unexpected increases in storage bills when access pattern change.\", 'When a minor version of a database engine is deprecated in Amazon RDS, we will provide a three (3) month period after the announcement before beginning automatic upgrades. At the end of this period, all instances still running the deprecated minor version will be scheduled for automatic upgrade to the latest supported minor version during their scheduled maintenance windows. When a major version of the database engine is deprecated in Amazon RDS, we will provide a minimum six (6) month period after the announcement of a deprecation for you to initiate an upgrade to a supported major version. At the end of this period, an automatic upgrade to the next major version will be applied to any instances still running the deprecated version during their scheduled maintenance windows. ', 'Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables compute in the cloud. The Amazon EC2 simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use.', 'Amazon RDS for PostgreSQL provides improved performance and scalability for PostgreSQL databases with features like Amazon Aurora.', 'S3 Access Points simplify how you manage data access to your shared datasets on S3. You no longer have to manage a single, complex bucket policy with hundreds of different permission rules that need to be written, read, tracked, and audited. With S3 Access Points, you can create access points or delegate permissions to trusted accounts to create cross-account access points on your bucket. This permits access to shared data sets with policies tailored to the specific application.', \"You pay only for what you use and there are no minimum or setup fees. You are billed based on: DB instance hours - Based on the class (e.g. db.t2.micro, db.m4.large) of the DB instance consumed. Partial DB instance hours consumed are billed in one-second increments with a 10 minute minimum charge following a billable status change, such as creating, starting, or modifying the DB instance class. For additional details, read our what's new announcement. Storage (per GB per month) - Storage capacity you have provisioned to your DB instance. If you scale your provisioned storage capacity within the month, your bill will be pro-rated. I/O requests per month - Total number of storage I/O requests you have (for Amazon RDS Magnetic Storage and Amazon Aurora only) Provisioned IOPS per month - Provisioned IOPS rate, regardless of IOPS consumed (for Amazon RDS Provisioned IOPS (SSD) Storage only) Backup Storage - Backup storage is the storage associated with your automated database backups and any customer-initiated database snapshots. Increasing your backup retention period or taking additional database snapshots increases the backup storage consumed by your database. Data transfer - Internet data transfer in and out of your DB instance. For Amazon RDS pricing information, please visit the pricing section on the Amazon RDS product page. \", 'Amazon S3 Event Notifications let you run workflows, send alerts, or perform other actions in response to changes in your objects stored in S3. You can use S3 Event Notifications to set up triggers to perform actions including transcoding media files when they are uploaded, processing data files when they become available, and synchronizing S3 objects with other data stores. You can also set up event notifications based on object name prefixes and suffixes. For example, you can choose to receive notifications on object names that start with images/.\"', 'Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.', 'Memory-optimized instances offer large memory size for memory intensive applications including in-memory applications, in-memory databases, in-memory analytics solutions, HPC, scientific computing, and other memory-intensive applications.', 'How can I manage my AWS Lambda functions? ', \"Read replicas make it easier to take advantage of supported engines' built-in replication functionality to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create a read replica with a few clicks in the AWS Management Console or using the CreateDBInstanceReadReplica API. Once the read replica is created, database updates on the source DB instance will be replicated using a supported engine's native, asynchronous replication. You can create multiple read replicas for a given source DB Instance and distribute your application's read traffic amongst them. Since read replicas use supported engines' built-in replication, they are subject to its strengths and limitations. In particular, updates are applied to your read replica(s) after they occur on the source DB instance, and replication lag can vary significantly. Read replicas can be associated with Multi-AZ deployments to gain read scaling benefits in addition to the enhanced database write availability and data durability provided by Multi-AZ deployments. \", 'Amazon RDS Blue/Green Deployments are available in for Amazon Aurora MySQL-Compatible Edition versions 5.6 and higher, RDS for MySQL versions 5.7 and higher, and RDS for versions MariaDB versions 10.2 and higher. Blue/Green Deployments are also supported for Amazon Aurora PostgreSQL-Compatible Edition and Amazon RDS for PostgreSQL for versions 11.21 and higher, 12.16 and higher, 13.12 and higher, 14.9 and higher, and 15.4 and higher. Learn more about available versions in the Amazon Aurora and Amazon RDS documentation. ', 'Yes. Your standby is automatically provisioned in a different Availability Zone of the same Region as your DB instance primary. ', 'S3 Access Grants is charged based on the number of requests to S3 Access Grants. See the pricing page for details.', \"Amazon S3 Transfer Acceleration creates fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. S3 Transfer Acceleration leverages Amazon CloudFront's globally distributed AWS Edge locations. As data arrives at an AWS Edge Location, data is routed to your Amazon S3 bucket over an optimized network path.\", \"Amazon S3 lets you leverage Amazon's own benefits of massive scale with no up-front investment or performance compromises. By using Amazon S3, it is inexpensive and simple to ensure your data is quickly accessible, always available, and secure.\", \"Using the RI Marketplace, you can set an upfront price you'd be willing to accept. You cannot set the hourly price (which will remain the same as was set on the original RI), and you will not receive any funds collected from payments associated with the hourly prices.\", 'You can start selling on the RI Marketplace after you have added a bank account through the registration pipeline. Once activation is complete, you will receive a confirmation email. However, it is important to note that you will not be able to receive disbursements until we are able to receive verification from your bank, which may take up to two weeks, depending on the bank you use.', 'Yes. You can tag an EC2 Fleet request to create business-relevant tag groupings to organize resources along technical, business, and security dimensions.', 'No, we do not support multi-region EC2 Fleet requests.', 'In the case of hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shut down and RAM is cleared.', 'Enhanced Monitoring for Amazon RDS gives you deeper visibility into the health of your Amazon RDS instances. Just turn on the  Enhanced Monitoring  option for your Amazon RDS DB Instance and set a granularity and Enhanced Monitoring will collect vital operating system metrics and process information, at the defined granularity. For an even deeper level of diagnostics and visualization of your database load, and a longer data retention period, you can try Performance Insights. ', 'Amazon S3 Access Grants map identities in directories such as Active Directory, or AWS Identity and Access Management (IAM) principals, to datasets in S3. This helps you manage data permissions at scale by automatically granting S3 access to end-users based on their corporate identity. Additionally, S3 Access Grants log end-user identity and the application used to access S3 data in AWS CloudTrail. This helps to provide a detailed audit history down to the end-user identity for all access to the data in your S3 buckets.', 'The code you run on AWS Lambda is uploaded as a Lambda function. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a stateless style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones. ', 'Amazon S3 delivers strong read-after-write consistency automatically, without changes to performance or availability, without sacrificing regional isolation for applications, and at no additional cost.', 'Amazon EC2 NVMe instance storage is encrypted using an XTS-AES-256 block cipher.', 'The Lambda Runtime Interface Emulator is a proxy for the Lambda Runtime API,which allows customers to locally test their Lambda function packaged as a container image. It is a lightweight web server that converts HTTP requests to JSON events and emulates the Lambda Runtime API. It allows you to locally test your functions using familiar tools such as cURL and the Docker CLI (when testing functions packaged as container images). It also simplifies running your application on additional compute services. You can include the Lambda Runtime Interface Emulator in your container image to have it accept HTTP requests natively instead of the JSON events required for deployment to Lambda. This component does not emulate the Lambda orchestrator, or security and authentication configurations. The Runtime Interface Emulator is open sourced on GitHub. You can get started by downloading and installing it on your local machine. ', 'Amazon RDS Proxy is a fully managed, highly available, and easy-to-use database proxy feature of Amazon RDS that enables your applications to: 1) improve scalability by pooling and sharing database connections, 2) improve availability by reducing database failover times by up to 66% and preserving application connections during failovers, and 3) improve security by optionally enforcing AWS IAM authentication to databases and securely storing credentials in AWS Secrets Manager. ', 'How can I manage my AWS Lambda functions? ', 'Dedicated Hosts offer the advantage of maximum visibility and control over the underlying physical servers. They provide predictability and isolation for your instances.', 'Consider using Amazon Aurora. It is a MySQL and PostgreSQL-compatible relational database engine designed for performance and scalability.', 'If your application needs durable, persistent storage, consider using Amazon S3 or Amazon EFS. If your application requires storing data needed by code in a single function invocation, consider using AWS Lambda ephemeral storage as a transient cache. To learn more, please see Choosing between AWS Lambda data storage options in web apps. ', 'Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1 and io2) and General Purpose SSD (gp2 and gp3). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O pattern. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information, see the Amazon EBS overview.', 'Versioning allows you to preserve, retrieve, and restore every version of every object stored in an Amazon S3 bucket. Once you enable Versioning for a bucket, Amazon S3 preserves existing objects anytime you perform a PUT, POST, COPY, or DELETE operation on them. By default, GET requests will retrieve the most recently written version. Older versions of an overwritten or deleted object can be retrieved by specifying a version in the request.', 'Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables compute in the cloud. The Amazon EC2 simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use.']\n"
     ]
    }
   ],
   "source": [
    "# print(rdf['response'].tolist())\n",
    "print(arr_of_predicted_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.15139442231075698\n"
     ]
    }
   ],
   "source": [
    "def precision_for_k(arr_of_actual_responses, arr_of_predicted_responses, k):\n",
    "    sum = 0\n",
    "\n",
    "    for i in range(len(arr_of_actual_responses)-1):\n",
    "        if (arr_of_actual_responses[i] == arr_of_predicted_responses[i]) :\n",
    "            \n",
    "            sum += 1\n",
    "    precision = sum / k if k > 0 else 0\n",
    "    print(f\"precision : {precision}\")\n",
    "\n",
    "k = len(rdf.index)\n",
    "precision_for_k(arr_of_actual_responses, arr_of_predicted_responses, k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0\n"
     ]
    }
   ],
   "source": [
    "def accuracy_for_k(arr_of_actual_responses, arr_of_predicted_responses):\n",
    "    correct_predictions = sum(1 for actual, predicted in zip(arr_of_actual_responses, arr_of_predicted_responses) if type(actual) in [int, float] and type(predicted) in [int, float] and actual == predicted)\n",
    "    total_predictions = sum(1 for actual in arr_of_actual_responses if type(actual) in [int, float])\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy_for_k(arr_of_actual_responses, arr_of_predicted_responses):\n",
    "    correct_predictions = sum(1 for actual, predicted in zip(arr_of_actual_responses, arr_of_predicted_responses) if actual == predicted)\n",
    "    total_predictions = len(arr_of_actual_responses)\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "accuracy_for_k(arr_of_actual_responses, arr_of_predicted_responses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
